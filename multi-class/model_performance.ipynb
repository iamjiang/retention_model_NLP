{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b281b79-6331-49fa-a324-ba3b96a8c139",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/test/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers version is 4.19.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from tqdm.auto import tqdm\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(position=0,leave=True)\n",
    "import random\n",
    "import argparse\n",
    "import logging\n",
    "\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score, f1_score,average_precision_score\n",
    "from sklearn.metrics import precision_recall_fscore_support \n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc as auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
    "\n",
    "import textwrap\n",
    "\n",
    "from datasets import load_dataset, load_metric, concatenate_datasets,DatasetDict,Dataset\n",
    "from datasets import load_from_disk\n",
    "\n",
    "import transformers\n",
    "print(\"Transformers version is {}\".format(transformers.__version__))\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    AutoConfig,\n",
    "    AutoModel,\n",
    "    AutoModelWithLMHead,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    default_data_collator,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    get_scheduler\n",
    ")\n",
    "\n",
    "import utils\n",
    "\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import rc\n",
    "\n",
    "sns.set(style=\"whitegrid\",palette='muted',font_scale=1.2)\n",
    "# rcParams['figure.figsize']=16,10\n",
    "\n",
    "%config InlineBackend.figure_format=\"retina\"\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "759d27b5-3334-4a04-9aca-9913aee18d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82d8d354-3a16-43b9-b932-199904e63b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2044010/2044010 [00:03<00:00, 678942.68it/s]\n"
     ]
    }
   ],
   "source": [
    "input_dir=\"s3://trident-retention-output/\"\n",
    "output_dir=\"s3://trident-retention-output/multi-class/\"\n",
    "\n",
    "askunum_text=pd.read_pickle(os.path.join(input_dir,\"askunum_text_v1\")) ## askunum_text_v1 group text by parentID and Subtype\n",
    "askunum_text['Subtype'] = askunum_text['Subtype'].fillna(\"\").astype(str).str.lower()\n",
    "askunum_text[\"Subtype\"]=askunum_text[\"Subtype\"].progress_apply(lambda x: x.encode(\"latin1\").decode(\"cp1252\"))\n",
    "askunum_text[\"Subtype\"]=askunum_text[\"Subtype\"].str.replace(\"/\",\" or \")\n",
    "askunum_text[\"Subtype\"]=askunum_text[\"Subtype\"].str.replace(\"&\",\" and \")\n",
    "askunum_text[\"Subtype\"]=askunum_text[\"Subtype\"].str.replace(r\"\\s{2,}\", \" \", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13c5ce65-1a46-4bcf-884b-58e8b22c3c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "args_val=['bill hide or delete', \"bill not received\", \"late notice or collections\", \"missing or skipped payment\",'policy level discrepancy', 'premium discrepancy', \n",
    "              'broker of record change (bor)','missing information','request to speak to dbs','less than minimum lives', 'policy termination','new plan administrator']\n",
    "\n",
    "sample_class=utils.Sample_Creation(askunum_text, *args_val)\n",
    "train_df, val_df, test_df=sample_class.data_creation(val_ratio=0.1, test_ratio=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e87bd0b-6244-4b8c-a258-fe28905c1119",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_distribution(df,col):\n",
    "        tempt1=pd.DataFrame(df[col].value_counts(dropna=False)).reset_index().rename(columns={'index':col,col:'count'})\n",
    "        tempt2=pd.DataFrame(df[col].value_counts(dropna=False,normalize=True)).reset_index().rename(columns={'index':col,col:'percentage'})\n",
    "        return tempt1.merge(tempt2, on=col, how=\"inner\")\n",
    "\n",
    "def style_format(df, col, data_type=\"Training set\"):\n",
    "    return df.style.format({'count':'{:,}','percentage':'{:.2%}'})\\\n",
    "           .set_caption(f\"{data_type} {col} distribution\")\\\n",
    "           .set_table_styles([{'selector': 'caption','props': [('color', 'red'),('font-size', '15px')]}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "763f3564-81e9-4d66-8b0a-2cc26c29a518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_9aeff caption {\n",
       "  color: red;\n",
       "  font-size: 15px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_9aeff\">\n",
       "  <caption>Training set Subtype distribution</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_9aeff_level0_col0\" class=\"col_heading level0 col0\" >Subtype</th>\n",
       "      <th id=\"T_9aeff_level0_col1\" class=\"col_heading level0 col1\" >count</th>\n",
       "      <th id=\"T_9aeff_level0_col2\" class=\"col_heading level0 col2\" >percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_9aeff_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_9aeff_row0_col0\" class=\"data row0 col0\" >policy termination</td>\n",
       "      <td id=\"T_9aeff_row0_col1\" class=\"data row0 col1\" >28,320</td>\n",
       "      <td id=\"T_9aeff_row0_col2\" class=\"data row0 col2\" >25.32%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9aeff_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_9aeff_row1_col0\" class=\"data row1 col0\" >missing information</td>\n",
       "      <td id=\"T_9aeff_row1_col1\" class=\"data row1 col1\" >23,712</td>\n",
       "      <td id=\"T_9aeff_row1_col2\" class=\"data row1 col2\" >21.20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9aeff_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_9aeff_row2_col0\" class=\"data row2 col0\" >broker of record change (bor)</td>\n",
       "      <td id=\"T_9aeff_row2_col1\" class=\"data row2 col1\" >17,451</td>\n",
       "      <td id=\"T_9aeff_row2_col2\" class=\"data row2 col2\" >15.60%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9aeff_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_9aeff_row3_col0\" class=\"data row3 col0\" >new plan administrator</td>\n",
       "      <td id=\"T_9aeff_row3_col1\" class=\"data row3 col1\" >16,087</td>\n",
       "      <td id=\"T_9aeff_row3_col2\" class=\"data row3 col2\" >14.38%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9aeff_level0_row4\" class=\"row_heading level0 row4\" >5</th>\n",
       "      <td id=\"T_9aeff_row4_col0\" class=\"data row4 col0\" >premium discrepancy</td>\n",
       "      <td id=\"T_9aeff_row4_col1\" class=\"data row4 col1\" >6,873</td>\n",
       "      <td id=\"T_9aeff_row4_col2\" class=\"data row4 col2\" >6.14%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9aeff_level0_row5\" class=\"row_heading level0 row5\" >6</th>\n",
       "      <td id=\"T_9aeff_row5_col0\" class=\"data row5 col0\" >bill not received</td>\n",
       "      <td id=\"T_9aeff_row5_col1\" class=\"data row5 col1\" >2,841</td>\n",
       "      <td id=\"T_9aeff_row5_col2\" class=\"data row5 col2\" >2.54%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9aeff_level0_row6\" class=\"row_heading level0 row6\" >7</th>\n",
       "      <td id=\"T_9aeff_row6_col0\" class=\"data row6 col0\" >late notice or collections</td>\n",
       "      <td id=\"T_9aeff_row6_col1\" class=\"data row6 col1\" >2,240</td>\n",
       "      <td id=\"T_9aeff_row6_col2\" class=\"data row6 col2\" >2.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9aeff_level0_row7\" class=\"row_heading level0 row7\" >8</th>\n",
       "      <td id=\"T_9aeff_row7_col0\" class=\"data row7 col0\" >missing or skipped payment</td>\n",
       "      <td id=\"T_9aeff_row7_col1\" class=\"data row7 col1\" >2,200</td>\n",
       "      <td id=\"T_9aeff_row7_col2\" class=\"data row7 col2\" >1.97%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9aeff_level0_row8\" class=\"row_heading level0 row8\" >9</th>\n",
       "      <td id=\"T_9aeff_row8_col0\" class=\"data row8 col0\" >policy level discrepancy</td>\n",
       "      <td id=\"T_9aeff_row8_col1\" class=\"data row8 col1\" >1,370</td>\n",
       "      <td id=\"T_9aeff_row8_col2\" class=\"data row8 col2\" >1.22%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9aeff_level0_row9\" class=\"row_heading level0 row9\" >10</th>\n",
       "      <td id=\"T_9aeff_row9_col0\" class=\"data row9 col0\" >less than minimum lives</td>\n",
       "      <td id=\"T_9aeff_row9_col1\" class=\"data row9 col1\" >1,031</td>\n",
       "      <td id=\"T_9aeff_row9_col2\" class=\"data row9 col2\" >0.92%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9aeff_level0_row10\" class=\"row_heading level0 row10\" >11</th>\n",
       "      <td id=\"T_9aeff_row10_col0\" class=\"data row10 col0\" >bill hide or delete</td>\n",
       "      <td id=\"T_9aeff_row10_col1\" class=\"data row10 col1\" >592</td>\n",
       "      <td id=\"T_9aeff_row10_col2\" class=\"data row10 col2\" >0.53%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9aeff_level0_row11\" class=\"row_heading level0 row11\" >12</th>\n",
       "      <td id=\"T_9aeff_row11_col0\" class=\"data row11 col0\" >request to speak to dbs</td>\n",
       "      <td id=\"T_9aeff_row11_col1\" class=\"data row11 col1\" >543</td>\n",
       "      <td id=\"T_9aeff_row11_col2\" class=\"data row11 col2\" >0.49%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9aeff_level0_row12\" class=\"row_heading level0 row12\" >4</th>\n",
       "      <td id=\"T_9aeff_row12_col0\" class=\"data row12 col0\" >other-category</td>\n",
       "      <td id=\"T_9aeff_row12_col1\" class=\"data row12 col1\" >8,604</td>\n",
       "      <td id=\"T_9aeff_row12_col2\" class=\"data row12 col2\" >7.69%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fc35c85fa90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_train=label_distribution(train_df,col=\"Subtype\")\n",
    "x1=label_train[label_train[\"Subtype\"] != \"other-category\"]\n",
    "x2=label_train[label_train[\"Subtype\"] == \"other-category\"]\n",
    "label_train=pd.concat([x1,x2])\n",
    "style_format(label_train,col=\"Subtype\",  data_type=\"Training set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b580e29-98c2-4043-9840-c685970c664c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a70e1 caption {\n",
       "  color: red;\n",
       "  font-size: 15px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a70e1\">\n",
       "  <caption>Test set Subtype distribution</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_a70e1_level0_col0\" class=\"col_heading level0 col0\" >Subtype</th>\n",
       "      <th id=\"T_a70e1_level0_col1\" class=\"col_heading level0 col1\" >count</th>\n",
       "      <th id=\"T_a70e1_level0_col2\" class=\"col_heading level0 col2\" >percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a70e1_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_a70e1_row0_col0\" class=\"data row0 col0\" >policy termination</td>\n",
       "      <td id=\"T_a70e1_row0_col1\" class=\"data row0 col1\" >3,540</td>\n",
       "      <td id=\"T_a70e1_row0_col2\" class=\"data row0 col2\" >25.33%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a70e1_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_a70e1_row1_col0\" class=\"data row1 col0\" >missing information</td>\n",
       "      <td id=\"T_a70e1_row1_col1\" class=\"data row1 col1\" >2,964</td>\n",
       "      <td id=\"T_a70e1_row1_col2\" class=\"data row1 col2\" >21.21%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a70e1_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_a70e1_row2_col0\" class=\"data row2 col0\" >broker of record change (bor)</td>\n",
       "      <td id=\"T_a70e1_row2_col1\" class=\"data row2 col1\" >2,181</td>\n",
       "      <td id=\"T_a70e1_row2_col2\" class=\"data row2 col2\" >15.60%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a70e1_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_a70e1_row3_col0\" class=\"data row3 col0\" >new plan administrator</td>\n",
       "      <td id=\"T_a70e1_row3_col1\" class=\"data row3 col1\" >2,010</td>\n",
       "      <td id=\"T_a70e1_row3_col2\" class=\"data row3 col2\" >14.38%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a70e1_level0_row4\" class=\"row_heading level0 row4\" >5</th>\n",
       "      <td id=\"T_a70e1_row4_col0\" class=\"data row4 col0\" >premium discrepancy</td>\n",
       "      <td id=\"T_a70e1_row4_col1\" class=\"data row4 col1\" >859</td>\n",
       "      <td id=\"T_a70e1_row4_col2\" class=\"data row4 col2\" >6.15%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a70e1_level0_row5\" class=\"row_heading level0 row5\" >6</th>\n",
       "      <td id=\"T_a70e1_row5_col0\" class=\"data row5 col0\" >bill not received</td>\n",
       "      <td id=\"T_a70e1_row5_col1\" class=\"data row5 col1\" >355</td>\n",
       "      <td id=\"T_a70e1_row5_col2\" class=\"data row5 col2\" >2.54%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a70e1_level0_row6\" class=\"row_heading level0 row6\" >7</th>\n",
       "      <td id=\"T_a70e1_row6_col0\" class=\"data row6 col0\" >late notice or collections</td>\n",
       "      <td id=\"T_a70e1_row6_col1\" class=\"data row6 col1\" >280</td>\n",
       "      <td id=\"T_a70e1_row6_col2\" class=\"data row6 col2\" >2.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a70e1_level0_row7\" class=\"row_heading level0 row7\" >8</th>\n",
       "      <td id=\"T_a70e1_row7_col0\" class=\"data row7 col0\" >missing or skipped payment</td>\n",
       "      <td id=\"T_a70e1_row7_col1\" class=\"data row7 col1\" >274</td>\n",
       "      <td id=\"T_a70e1_row7_col2\" class=\"data row7 col2\" >1.96%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a70e1_level0_row8\" class=\"row_heading level0 row8\" >9</th>\n",
       "      <td id=\"T_a70e1_row8_col0\" class=\"data row8 col0\" >policy level discrepancy</td>\n",
       "      <td id=\"T_a70e1_row8_col1\" class=\"data row8 col1\" >171</td>\n",
       "      <td id=\"T_a70e1_row8_col2\" class=\"data row8 col2\" >1.22%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a70e1_level0_row9\" class=\"row_heading level0 row9\" >10</th>\n",
       "      <td id=\"T_a70e1_row9_col0\" class=\"data row9 col0\" >less than minimum lives</td>\n",
       "      <td id=\"T_a70e1_row9_col1\" class=\"data row9 col1\" >128</td>\n",
       "      <td id=\"T_a70e1_row9_col2\" class=\"data row9 col2\" >0.92%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a70e1_level0_row10\" class=\"row_heading level0 row10\" >11</th>\n",
       "      <td id=\"T_a70e1_row10_col0\" class=\"data row10 col0\" >bill hide or delete</td>\n",
       "      <td id=\"T_a70e1_row10_col1\" class=\"data row10 col1\" >73</td>\n",
       "      <td id=\"T_a70e1_row10_col2\" class=\"data row10 col2\" >0.52%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a70e1_level0_row11\" class=\"row_heading level0 row11\" >12</th>\n",
       "      <td id=\"T_a70e1_row11_col0\" class=\"data row11 col0\" >request to speak to dbs</td>\n",
       "      <td id=\"T_a70e1_row11_col1\" class=\"data row11 col1\" >67</td>\n",
       "      <td id=\"T_a70e1_row11_col2\" class=\"data row11 col2\" >0.48%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a70e1_level0_row12\" class=\"row_heading level0 row12\" >4</th>\n",
       "      <td id=\"T_a70e1_row12_col0\" class=\"data row12 col0\" >other-category</td>\n",
       "      <td id=\"T_a70e1_row12_col1\" class=\"data row12 col1\" >1,075</td>\n",
       "      <td id=\"T_a70e1_row12_col2\" class=\"data row12 col2\" >7.69%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fc0f15288e0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_test=label_distribution(test_df,col=\"Subtype\")\n",
    "x1=label_test[label_test[\"Subtype\"] != \"other-category\"]\n",
    "x2=label_test[label_test[\"Subtype\"] == \"other-category\"]\n",
    "label_test=pd.concat([x1,x2])\n",
    "style_format(label_test,col=\"Subtype\",  data_type=\"Test set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1644b943-2200-4a78-a22a-bd70eff4d601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper = textwrap.TextWrapper(width=150) \n",
    "# # Randomly choose some examples.\n",
    "# for i in range(10):\n",
    "#     random.seed(101+i)\n",
    "\n",
    "#     j = random.choice(train_df.index)\n",
    "#     emails=train_df.loc[j,\"TextBody\"]\n",
    "#     subtype=train_df.loc[j,\"Subtype\"]\n",
    "\n",
    "#     print('')\n",
    "#     print(\"*\"*80)\n",
    "#     print(f'*  Full TextBody :   subtype={subtype} *')\n",
    "#     print(\"*\"*80)\n",
    "#     print('')\n",
    "#     # print(j)\n",
    "#     print(wrapper.fill(emails))\n",
    "#     print('')\n",
    "#     print(\"*\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14209148-fb59-440c-a490-13b51c78710c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a84f0bd5-8d86-497a-8815-502817eb9da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=64, feature_name='TextBody', gpus=[0, 1], is_train_inference=False, loss_weight=True, model_path='/home/ec2-user/SageMaker/retention_model_NLP/multi-class/roberta_large_repo', seed=101, shuffle_train=True, test_ratio=0.1, truncation_strategy='head', val_ratio=0.1)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='Model Inference')\n",
    "parser.add_argument('--gpus', type=int, default=[0,1], nargs='+', help='used gpu')\n",
    "parser.add_argument(\"--shuffle_train\",  type=bool,default=True,help=\"shuffle data or not\")\n",
    "parser.add_argument('--val_ratio', type=float, default=0.1)\n",
    "parser.add_argument('--test_ratio', type=float, default=0.1)\n",
    "parser.add_argument(\"--loss_weight\", action='store_true', help=\"weight for unbalance data\")\n",
    "parser.add_argument(\"--seed\",  type=int,default=101,\n",
    "        help=\"random seed for np.random.seed, torch.manual_seed and torch.cuda.manual_seed.\")\n",
    "\n",
    "parser.add_argument(\"--truncation_strategy\", type=str, default=\"head\",help=\"how to truncate the long length email\")\n",
    "parser.add_argument(\"--batch_size\", type=int, default=8)\n",
    "parser.add_argument(\"--model_path\",type=str,default=\"/home/ec2-user/SageMaker/retention_model_NLP/multi-class/roberta_large_repo\")\n",
    "parser.add_argument(\"--feature_name\", default=\"TextBody\", type=str)\n",
    "parser.add_argument(\"--is_train_inference\", action=\"store_true\", help=\"inference for training set or not\")\n",
    "\n",
    "args,_= parser.parse_known_args()\n",
    "\n",
    "args.loss_weight=True\n",
    "args.batch_size=64\n",
    "\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "030d05e0-850e-4d47-b6e8-91887fcb5803",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 126/126 [00:00<00:00, 204.21ba/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 204.31ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The maximal # input tokens : 512\n",
      "Vocabulary size : 50,265\n",
      "The # of parameters : 355,373,069\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/126 [00:00<?, ?ba/s]Token indices sequence length is longer than the specified maximum sequence length for this model (523 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 126/126 [00:17<00:00,  7.01ba/s]\n",
      "100%|██████████| 14/14 [00:01<00:00,  7.26ba/s]\n",
      "100%|██████████| 125847/125847 [02:42<00:00, 772.68ex/s]\n",
      "100%|██████████| 13977/13977 [00:17<00:00, 800.49ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The # of availabe GPU(s):     2         \n",
      "GPU Name:                     NVIDIA A10G\n",
      "GPU Name:                     NVIDIA A10G\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 126/126 [00:20<00:00,  6.04ba/s]\n",
      "100%|██████████| 14/14 [00:02<00:00,  5.77ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training mini-batch           1,967      \n",
      "test mini-batch               219        \n"
     ]
    }
   ],
   "source": [
    "seed_everything(args.seed)\n",
    "\n",
    "#convert categorical target variable into integer target variable\n",
    "def cate_2_int_label(df,col):\n",
    "    uniq_label=df[col].unique()\n",
    "    uniq_label.sort()\n",
    "    label_map={v:idx for idx,v in enumerate(uniq_label)}\n",
    "    df[col]=list(map(label_map.get, df[col]))\n",
    "    df = df.rename(columns={col: 'label'})\n",
    "    return df, label_map\n",
    "\n",
    "train_df, train_label_map=cate_2_int_label(train_df,col=\"Subtype\")\n",
    "val_df, val_label_map=cate_2_int_label(val_df,col=\"Subtype\")\n",
    "test_df, test_label_map=cate_2_int_label(test_df,col=\"Subtype\")\n",
    "\n",
    "# train_df=train_df.sample(n=1000)\n",
    "# val_df=val_df.sample(n=1000)\n",
    "# test_df=test_df.sample(n=1000)\n",
    "\n",
    "hf_train=Dataset.from_pandas(train_df)\n",
    "hf_val=Dataset.from_pandas(val_df)\n",
    "hf_test=Dataset.from_pandas(test_df)\n",
    "# hf_data=DatasetDict({\"train\":hf_train, \"val\":hf_val,  \"test\":hf_test})\n",
    "hf_data=concatenate_datasets([hf_train,  hf_val],split=\"train\")\n",
    "hf_data=DatasetDict({\"train\":hf_data, \"test\":hf_test})\n",
    "\n",
    "hf_data=hf_data.filter(lambda x: x[args.feature_name]!=None)\n",
    "\n",
    "train_label=train_df['label'].values.squeeze()\n",
    "num_classes=np.unique(train_label).shape[0]\n",
    "\n",
    "tokenizer=AutoTokenizer.from_pretrained(args.model_path)\n",
    "model=AutoModelForSequenceClassification.from_pretrained(args.model_path, num_labels = num_classes)\n",
    "\n",
    "print()\n",
    "print(f\"The maximal # input tokens : {tokenizer.model_max_length:,}\")\n",
    "print(f\"Vocabulary size : {tokenizer.vocab_size:,}\")\n",
    "print(f\"The # of parameters : {sum([p.nelement() for p in model.parameters()]):,}\")\n",
    "print()\n",
    "\n",
    "hf_data=hf_data.map(lambda x: tokenizer(x[args.feature_name]),batched=True)\n",
    "\n",
    "max_seq_length=tokenizer.model_max_length\n",
    "def truncation_text(example):\n",
    "    truncated_input_ids=tokenizer(example[args.feature_name],truncation=True,padding=False,return_tensors=\"pt\",add_special_tokens=False)['input_ids']\n",
    "\n",
    "    if args.truncation_strategy==\"tail\":\n",
    "        truncated_input_ids=truncated_input_ids[:,-(max_seq_length - 2):].squeeze()\n",
    "    elif args.truncation_strategy==\"head\":\n",
    "        truncated_input_ids=truncated_input_ids[:,0:(max_seq_length - 2)].squeeze()\n",
    "    elif args.truncation_strategy==\"mixed\":\n",
    "        truncated_input_ids=truncated_input_ids[:(max_seq_length - 2) // 2] + truncated_input_ids[-((max_seq_length - 2) // 2):]\n",
    "        truncated_input_ids=truncated_input_ids.squeeze()\n",
    "    else:\n",
    "        raise NotImplemented(\"Unknown truncation. Supported truncation: tail, head, mixed truncation\")\n",
    "\n",
    "    return {\"truncated_text\":tokenizer.decode(truncated_input_ids)}\n",
    "\n",
    "hf_data=hf_data.map(truncation_text)\n",
    "columns=hf_data['train'].column_names\n",
    "columns_to_keep=['truncated_text','label']\n",
    "columns_to_remove=set(columns)-set(columns_to_keep)\n",
    "hf_data=hf_data.remove_columns(columns_to_remove)\n",
    "hf_data=hf_data.rename_column(\"truncated_text\", args.feature_name)\n",
    "\n",
    "train_data=hf_data['train'].shuffle(seed=101).select(range(len(hf_data[\"train\"])))\n",
    "# val_data=hf_data['val'].shuffle(seed=101).select(range(len(hf_data[\"val\"])))\n",
    "test_data=hf_data['test'].shuffle(seed=101).select(range(len(hf_data[\"test\"])))\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ','.join(str(x) for x in args.gpus)\n",
    "# print(f\"The number of GPUs is {torch.cuda.device_count()}\")\n",
    "if torch.cuda.is_available():    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print()\n",
    "    print('{:<30}{:<10}'.format(\"The # of availabe GPU(s): \",torch.cuda.device_count()))\n",
    "\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print('{:<30}{:<10}'.format(\"GPU Name: \",torch.cuda.get_device_name(i)))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "train_data.set_format(type=\"pandas\")\n",
    "df_train=train_data[:]\n",
    "test_data.set_format(type=\"pandas\")\n",
    "df_test=test_data[:]\n",
    "\n",
    "train_data=Dataset.from_pandas(df_train)\n",
    "test_data=Dataset.from_pandas(df_test)\n",
    "\n",
    "\n",
    "train_module=utils.Loader_Creation(train_data, tokenizer,args.feature_name)\n",
    "\n",
    "\n",
    "test_module=utils.Loader_Creation(test_data, tokenizer,args.feature_name)\n",
    "\n",
    "train_data.set_format(type=\"pandas\")\n",
    "df_train=train_data[:]\n",
    "train_data.reset_format()\n",
    "\n",
    "train_dataloader=DataLoader(train_module,\n",
    "                            shuffle=True,\n",
    "                            batch_size=args.batch_size,\n",
    "                            collate_fn=train_module.collate_fn,\n",
    "                            drop_last=False   # longformer model bug\n",
    "                           )\n",
    "\n",
    "test_dataloader=DataLoader(test_module,\n",
    "                            shuffle=False,\n",
    "                            batch_size=args.batch_size,\n",
    "                            collate_fn=test_module.collate_fn\n",
    "                           )\n",
    "\n",
    "print()\n",
    "print('{:<30}{:<10,} '.format(\"training mini-batch\",len(train_dataloader)))\n",
    "#     print('{:<30}{:<10,} '.format(\"validation mini-batch\",len(valid_dataloader)))\n",
    "print('{:<30}{:<10,} '.format(\"test mini-batch\",len(test_dataloader)))\n",
    "\n",
    "\n",
    "if args.loss_weight:\n",
    "    train_classes_num, train_classes_weight = utils.get_class_count_and_weight(train_label,num_classes)\n",
    "    loss_weight=torch.tensor(train_classes_weight).to(device)\n",
    "else:\n",
    "    loss_weight=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc907c9a-9413-4b2f-895d-2bf7993cf1da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5acf95d-4f59-4828-aa8c-db521a971749",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluate(y_test, pred_test):\n",
    "    \n",
    "    ## convert logits into probability\n",
    "    pred_test=torch.nn.functional.softmax(torch.from_numpy(pred_test),dim=1).numpy()\n",
    "    \n",
    "    # acc = np.sum(pred_test.argmax(axis=1) == y_test.squeeze()) / y_test.shape[0]\n",
    "    prec_macro, recall_macro, fscore_macro, _ = precision_recall_fscore_support(y_test.squeeze(), pred_test.argmax(axis=1), average='macro')\n",
    "    prec_micro, recall_micro, fscore_micro, _ = precision_recall_fscore_support(y_test.squeeze(), pred_test.argmax(axis=1), average='micro')\n",
    "    prec_weighted, recall_weighted, fscore_weighted, _ = precision_recall_fscore_support(y_test.squeeze(), pred_test.argmax(axis=1), average='weighted')\n",
    "    \n",
    "    macro_roc_auc_ovo=roc_auc_score(y_test,pred_test,multi_class=\"ovo\",average=\"macro\")\n",
    "    weighted_roc_auc_ovo=roc_auc_score(y_test,pred_test,multi_class=\"ovo\",average=\"weighted\")\n",
    "\n",
    "    macro_roc_auc_ovr=roc_auc_score(y_test,pred_test,multi_class=\"ovr\",average=\"macro\")\n",
    "    weighted_roc_auc_ovr=roc_auc_score(y_test,pred_test,multi_class=\"ovr\",average=\"weighted\")\n",
    "    \n",
    "    \n",
    "    _, count=np.unique(y_test,return_counts=True)\n",
    "    weight=count/count.sum()\n",
    "    \n",
    "    y_test_binary=label_binarize(y_test, classes=np.unique(y_test).tolist())\n",
    "    n_classes = y_test_binary.shape[1]\n",
    "    \n",
    "    acc = dict()\n",
    "    for i in range(n_classes):\n",
    "        mask=(y_test==i)\n",
    "        acc[i]=np.sum(pred_test[mask].argmax(axis=1) == i) / np.sum(mask)    \n",
    "    acc[\"micro\"] = np.sum(pred_test.argmax(axis=1) == y_test.squeeze()) / y_test.shape[0]\n",
    "    acc[\"macro\"]=0\n",
    "    acc[\"weighted\"]=0   \n",
    "    for i in range(n_classes):\n",
    "        acc[\"macro\"]+=acc[i]\n",
    "        acc[\"weighted\"]+=acc[i]*weight[i]\n",
    "    acc[\"macro\"]/=n_classes\n",
    "    \n",
    "    roc_auc = dict()\n",
    "    pr_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr, tpr, _ = roc_curve(y_test_binary[:, i],pred_test[:, i])\n",
    "        roc_auc[i] = auc_score(fpr, tpr)\n",
    "        \n",
    "        prec,rec,_ = precision_recall_curve(y_test_binary[:, i], torch.sigmoid(torch.from_numpy(pred_test))[:,i].numpy())\n",
    "        pr_auc[i]=auc_score(rec,prec)\n",
    "    \n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr, tpr, _ = roc_curve(y_test_binary.ravel(), pred_test.ravel())\n",
    "    roc_auc[\"micro\"] = auc_score(fpr, tpr)\n",
    "    roc_auc[\"macro\"]=0\n",
    "    roc_auc[\"weighted\"]=0\n",
    "    for i in range(n_classes):\n",
    "        roc_auc[\"macro\"]+=roc_auc[i]\n",
    "        roc_auc[\"weighted\"]+=roc_auc[i]*weight[i]\n",
    "    roc_auc[\"macro\"]/=n_classes\n",
    "    \n",
    "    prec,rec,_ = precision_recall_curve(y_test_binary.ravel(), torch.sigmoid(torch.from_numpy(pred_test)).numpy().ravel())\n",
    "    pr_auc[\"micro\"]=auc_score(rec,prec)\n",
    "\n",
    "    pr_auc[\"macro\"]=0\n",
    "    pr_auc[\"weighted\"]=0\n",
    "    for i in range(n_classes):\n",
    "        pr_auc[\"macro\"]+=pr_auc[i]\n",
    "        pr_auc[\"weighted\"]+=pr_auc[i]*weight[i]\n",
    "    pr_auc[\"macro\"]/=n_classes\n",
    "\n",
    "    metrics = {}\n",
    "    \n",
    "    metrics['prec_macro'] = prec_macro\n",
    "    metrics['recall_macro'] = recall_macro\n",
    "    metrics['fscore_macro'] = fscore_macro\n",
    "    metrics['acc_macro'] = acc[\"macro\"]\n",
    "\n",
    "    metrics['prec_micro'] = prec_micro\n",
    "    metrics['recall_micro'] = recall_micro\n",
    "    metrics['fscore_micro'] = fscore_micro\n",
    "    metrics['acc_micro'] = acc[\"micro\"]\n",
    "\n",
    "    metrics['prec_weighted'] = prec_weighted\n",
    "    metrics['recall_weighted'] = recall_weighted\n",
    "    metrics['fscore_weighted'] = fscore_weighted\n",
    "    metrics['acc_weighted'] = acc[\"weighted\"]\n",
    "    \n",
    "    metrics['auc_micro']=roc_auc[\"micro\"]\n",
    "    \n",
    "    metrics['auc_macro_ovo']=macro_roc_auc_ovo\n",
    "    metrics['auc_macro_ovr']=macro_roc_auc_ovr\n",
    "    \n",
    "    metrics['auc_weighted_ovo']=weighted_roc_auc_ovo\n",
    "    metrics['auc_weighted_ovr']=weighted_roc_auc_ovr  \n",
    "    \n",
    "    metrics['pr_auc_micro']=pr_auc[\"micro\"]\n",
    "    metrics['pr_auc_macro']=pr_auc[\"macro\"]\n",
    "    metrics['pr_auc_weighted']=pr_auc[\"weighted\"]\n",
    "\n",
    "    return metrics, acc, roc_auc, pr_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53c44e0-d182-40ad-87ea-999e41fd33f0",
   "metadata": {},
   "source": [
    "### Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c097f2-dc4d-4044-9eec-fcac803b3cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 378/1967 [08:42<36:35,  1.38s/it]"
     ]
    }
   ],
   "source": [
    "y_pred, y_target, losses_tmp=utils.eval_func(train_dataloader,model,device,num_classes=num_classes,loss_weight=loss_weight)\n",
    "label_map={v:k for k,v in train_label_map.items()}\n",
    "\n",
    "print()\n",
    "print(label_map)\n",
    "print()\n",
    "\n",
    "n_classes=len(label_map)\n",
    "\n",
    "metrics_dict, acc, roc_auc, pr_auc = model_evaluate(y_target,y_pred)\n",
    "report=metrics.classification_report(y_target.squeeze(), y_pred.argmax(axis=1), output_dict=True)\n",
    "\n",
    "table = pd.DataFrame(report).transpose().iloc[:n_classes,:]\n",
    "table[\"count\"]=table[\"support\"].astype(int)\n",
    "table[\"accuracy\"]=[acc[i] for i in range(n_classes)]\n",
    "# table[\"roc_auc\"]=[roc_auc[i] for i in range(n_classes)]\n",
    "table[\"pr_auc\"]=[pr_auc[i] for i in range(n_classes)]\n",
    "table[\"subtype_type\"]=[label_map[i] for i in range(n_classes)]\n",
    "table=table[['subtype_type','count','accuracy','precision','recall','f1-score','pr_auc']]\n",
    "\n",
    "total=table['count'].sum()\n",
    "\n",
    "table.loc[len(table.index)]=[\"MACRO\",total,metrics_dict['acc_macro'],metrics_dict['prec_macro'],metrics_dict['recall_macro'],metrics_dict['fscore_macro'],metrics_dict['pr_auc_macro']]\n",
    "\n",
    "table.loc[len(table.index)]=[\"MICRO\",total,metrics_dict['acc_micro'],metrics_dict['prec_micro'],metrics_dict['recall_micro'],metrics_dict['fscore_micro'],metrics_dict['pr_auc_micro']]\n",
    "\n",
    "table.loc[len(table.index)]=[\"WEIGHT\",total,metrics_dict['acc_weighted'],metrics_dict['prec_weighted'],metrics_dict['recall_weighted'],metrics_dict['fscore_weighted'],metrics_dict['pr_auc_weighted']]\n",
    "\n",
    "table.style.format({\"count\":\"{:,}\",\"accuracy\":\"{:.2%}\",\"f1-score\":\"{:.2%}\",\"precision\":\"{:.2%}\",\"recall\":\"{:.2%}\",\"pr_auc\":\"{:.2%}\"})\n",
    "\n",
    "# print()\n",
    "# print(\"{:<20}{:<10.2%}\".format(\"accuracy\", metrics_dict['acc']))\n",
    "# print()\n",
    "# print(\"{:<20}{:<10,.2%}{:<16}{:<10,.2%}{:<18}{:<10,.2%}{:<17}{:<10,.2%}{:<16}{:<10,.2%}\"\\\n",
    "#       .format(\"precision(macro):\",metrics_dict['prec_macro'],\"recall(macro):\",metrics_dict['recall_macro'],\\\n",
    "#               \"f1-score(macro):\",metrics_dict['fscore_macro'],\"ROC-AUC(macro):\",metrics_dict['auc_macro_ovo'],\\\n",
    "#              \"PR-AUC(macro):\",metrics_dict['pr_auc_macro']))\n",
    "\n",
    "# print(\"{:<20}{:<10,.2%}{:<16}{:<10,.2%}{:<18}{:<10,.2%}{:<17}{:<10,.2%}{:<16}{:<10,.2%}\"\\\n",
    "#       .format(\"precision(micro):\",metrics_dict['prec_micro'],\"recall(micro):\",metrics_dict['recall_micro'],\\\n",
    "#               \"f1-score(micro):\",metrics_dict['fscore_micro'],\"ROC-AUC(micro):\",metrics_dict['auc_micro'],\\\n",
    "#              \"PR-AUC(micro):\",metrics_dict['pr_auc_micro']))\n",
    "\n",
    "# print(\"{:<20}{:<10,.2%}{:<16}{:<10,.2%}{:<18}{:<10,.2%}{:<17}{:<10,.2%}{:<16}{:<10,.2%}\"\\\n",
    "#       .format(\"precision(weight):\",metrics_dict['prec_weighted'],\"recall(weight):\",metrics_dict['recall_weighted'],\\\n",
    "#               \"f1-score(weight):\",metrics_dict['fscore_weighted'],\"ROC-AUC(weight):\",metrics_dict['auc_weighted_ovo'],\\\n",
    "#              \"PR-AUC(weight):\",metrics_dict['pr_auc_weighted']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c5cd59-8c70-4a55-bfa1-a282d69ac646",
   "metadata": {},
   "source": [
    "### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "361a2008-d9f1-40b1-95b4-f06917e5e300",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 219/219 [05:01<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{0: 'bill hide or delete', 1: 'bill not received', 2: 'broker of record change (bor)', 3: 'late notice or collections', 4: 'less than minimum lives', 5: 'missing information', 6: 'missing or skipped payment', 7: 'new plan administrator', 8: 'other-category', 9: 'policy level discrepancy', 10: 'policy termination', 11: 'premium discrepancy', 12: 'request to speak to dbs'}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_54b88\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_54b88_level0_col0\" class=\"col_heading level0 col0\" >subtype_type</th>\n",
       "      <th id=\"T_54b88_level0_col1\" class=\"col_heading level0 col1\" >count</th>\n",
       "      <th id=\"T_54b88_level0_col2\" class=\"col_heading level0 col2\" >accuracy</th>\n",
       "      <th id=\"T_54b88_level0_col3\" class=\"col_heading level0 col3\" >precision</th>\n",
       "      <th id=\"T_54b88_level0_col4\" class=\"col_heading level0 col4\" >recall</th>\n",
       "      <th id=\"T_54b88_level0_col5\" class=\"col_heading level0 col5\" >f1-score</th>\n",
       "      <th id=\"T_54b88_level0_col6\" class=\"col_heading level0 col6\" >pr_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_54b88_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_54b88_row0_col0\" class=\"data row0 col0\" >bill hide or delete</td>\n",
       "      <td id=\"T_54b88_row0_col1\" class=\"data row0 col1\" >73</td>\n",
       "      <td id=\"T_54b88_row0_col2\" class=\"data row0 col2\" >80.82%</td>\n",
       "      <td id=\"T_54b88_row0_col3\" class=\"data row0 col3\" >60.82%</td>\n",
       "      <td id=\"T_54b88_row0_col4\" class=\"data row0 col4\" >80.82%</td>\n",
       "      <td id=\"T_54b88_row0_col5\" class=\"data row0 col5\" >69.41%</td>\n",
       "      <td id=\"T_54b88_row0_col6\" class=\"data row0 col6\" >70.20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_54b88_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_54b88_row1_col0\" class=\"data row1 col0\" >bill not received</td>\n",
       "      <td id=\"T_54b88_row1_col1\" class=\"data row1 col1\" >355</td>\n",
       "      <td id=\"T_54b88_row1_col2\" class=\"data row1 col2\" >76.90%</td>\n",
       "      <td id=\"T_54b88_row1_col3\" class=\"data row1 col3\" >57.72%</td>\n",
       "      <td id=\"T_54b88_row1_col4\" class=\"data row1 col4\" >76.90%</td>\n",
       "      <td id=\"T_54b88_row1_col5\" class=\"data row1 col5\" >65.94%</td>\n",
       "      <td id=\"T_54b88_row1_col6\" class=\"data row1 col6\" >71.82%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_54b88_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_54b88_row2_col0\" class=\"data row2 col0\" >broker of record change (bor)</td>\n",
       "      <td id=\"T_54b88_row2_col1\" class=\"data row2 col1\" >2,181</td>\n",
       "      <td id=\"T_54b88_row2_col2\" class=\"data row2 col2\" >94.13%</td>\n",
       "      <td id=\"T_54b88_row2_col3\" class=\"data row2 col3\" >95.18%</td>\n",
       "      <td id=\"T_54b88_row2_col4\" class=\"data row2 col4\" >94.13%</td>\n",
       "      <td id=\"T_54b88_row2_col5\" class=\"data row2 col5\" >94.65%</td>\n",
       "      <td id=\"T_54b88_row2_col6\" class=\"data row2 col6\" >98.28%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_54b88_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_54b88_row3_col0\" class=\"data row3 col0\" >late notice or collections</td>\n",
       "      <td id=\"T_54b88_row3_col1\" class=\"data row3 col1\" >280</td>\n",
       "      <td id=\"T_54b88_row3_col2\" class=\"data row3 col2\" >68.57%</td>\n",
       "      <td id=\"T_54b88_row3_col3\" class=\"data row3 col3\" >53.19%</td>\n",
       "      <td id=\"T_54b88_row3_col4\" class=\"data row3 col4\" >68.57%</td>\n",
       "      <td id=\"T_54b88_row3_col5\" class=\"data row3 col5\" >59.91%</td>\n",
       "      <td id=\"T_54b88_row3_col6\" class=\"data row3 col6\" >61.37%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_54b88_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_54b88_row4_col0\" class=\"data row4 col0\" >less than minimum lives</td>\n",
       "      <td id=\"T_54b88_row4_col1\" class=\"data row4 col1\" >128</td>\n",
       "      <td id=\"T_54b88_row4_col2\" class=\"data row4 col2\" >78.12%</td>\n",
       "      <td id=\"T_54b88_row4_col3\" class=\"data row4 col3\" >52.36%</td>\n",
       "      <td id=\"T_54b88_row4_col4\" class=\"data row4 col4\" >78.12%</td>\n",
       "      <td id=\"T_54b88_row4_col5\" class=\"data row4 col5\" >62.70%</td>\n",
       "      <td id=\"T_54b88_row4_col6\" class=\"data row4 col6\" >75.02%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_54b88_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_54b88_row5_col0\" class=\"data row5 col0\" >missing information</td>\n",
       "      <td id=\"T_54b88_row5_col1\" class=\"data row5 col1\" >2,964</td>\n",
       "      <td id=\"T_54b88_row5_col2\" class=\"data row5 col2\" >92.68%</td>\n",
       "      <td id=\"T_54b88_row5_col3\" class=\"data row5 col3\" >98.99%</td>\n",
       "      <td id=\"T_54b88_row5_col4\" class=\"data row5 col4\" >92.68%</td>\n",
       "      <td id=\"T_54b88_row5_col5\" class=\"data row5 col5\" >95.73%</td>\n",
       "      <td id=\"T_54b88_row5_col6\" class=\"data row5 col6\" >99.15%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_54b88_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_54b88_row6_col0\" class=\"data row6 col0\" >missing or skipped payment</td>\n",
       "      <td id=\"T_54b88_row6_col1\" class=\"data row6 col1\" >274</td>\n",
       "      <td id=\"T_54b88_row6_col2\" class=\"data row6 col2\" >43.07%</td>\n",
       "      <td id=\"T_54b88_row6_col3\" class=\"data row6 col3\" >43.38%</td>\n",
       "      <td id=\"T_54b88_row6_col4\" class=\"data row6 col4\" >43.07%</td>\n",
       "      <td id=\"T_54b88_row6_col5\" class=\"data row6 col5\" >43.22%</td>\n",
       "      <td id=\"T_54b88_row6_col6\" class=\"data row6 col6\" >44.85%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_54b88_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_54b88_row7_col0\" class=\"data row7 col0\" >new plan administrator</td>\n",
       "      <td id=\"T_54b88_row7_col1\" class=\"data row7 col1\" >2,010</td>\n",
       "      <td id=\"T_54b88_row7_col2\" class=\"data row7 col2\" >92.44%</td>\n",
       "      <td id=\"T_54b88_row7_col3\" class=\"data row7 col3\" >95.63%</td>\n",
       "      <td id=\"T_54b88_row7_col4\" class=\"data row7 col4\" >92.44%</td>\n",
       "      <td id=\"T_54b88_row7_col5\" class=\"data row7 col5\" >94.00%</td>\n",
       "      <td id=\"T_54b88_row7_col6\" class=\"data row7 col6\" >97.70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_54b88_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_54b88_row8_col0\" class=\"data row8 col0\" >other-category</td>\n",
       "      <td id=\"T_54b88_row8_col1\" class=\"data row8 col1\" >1,075</td>\n",
       "      <td id=\"T_54b88_row8_col2\" class=\"data row8 col2\" >66.23%</td>\n",
       "      <td id=\"T_54b88_row8_col3\" class=\"data row8 col3\" >58.89%</td>\n",
       "      <td id=\"T_54b88_row8_col4\" class=\"data row8 col4\" >66.23%</td>\n",
       "      <td id=\"T_54b88_row8_col5\" class=\"data row8 col5\" >62.35%</td>\n",
       "      <td id=\"T_54b88_row8_col6\" class=\"data row8 col6\" >63.85%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_54b88_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_54b88_row9_col0\" class=\"data row9 col0\" >policy level discrepancy</td>\n",
       "      <td id=\"T_54b88_row9_col1\" class=\"data row9 col1\" >171</td>\n",
       "      <td id=\"T_54b88_row9_col2\" class=\"data row9 col2\" >8.19%</td>\n",
       "      <td id=\"T_54b88_row9_col3\" class=\"data row9 col3\" >12.96%</td>\n",
       "      <td id=\"T_54b88_row9_col4\" class=\"data row9 col4\" >8.19%</td>\n",
       "      <td id=\"T_54b88_row9_col5\" class=\"data row9 col5\" >10.04%</td>\n",
       "      <td id=\"T_54b88_row9_col6\" class=\"data row9 col6\" >14.14%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_54b88_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_54b88_row10_col0\" class=\"data row10 col0\" >policy termination</td>\n",
       "      <td id=\"T_54b88_row10_col1\" class=\"data row10 col1\" >3,540</td>\n",
       "      <td id=\"T_54b88_row10_col2\" class=\"data row10 col2\" >92.68%</td>\n",
       "      <td id=\"T_54b88_row10_col3\" class=\"data row10 col3\" >97.42%</td>\n",
       "      <td id=\"T_54b88_row10_col4\" class=\"data row10 col4\" >92.68%</td>\n",
       "      <td id=\"T_54b88_row10_col5\" class=\"data row10 col5\" >94.99%</td>\n",
       "      <td id=\"T_54b88_row10_col6\" class=\"data row10 col6\" >98.62%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_54b88_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_54b88_row11_col0\" class=\"data row11 col0\" >premium discrepancy</td>\n",
       "      <td id=\"T_54b88_row11_col1\" class=\"data row11 col1\" >859</td>\n",
       "      <td id=\"T_54b88_row11_col2\" class=\"data row11 col2\" >70.90%</td>\n",
       "      <td id=\"T_54b88_row11_col3\" class=\"data row11 col3\" >66.78%</td>\n",
       "      <td id=\"T_54b88_row11_col4\" class=\"data row11 col4\" >70.90%</td>\n",
       "      <td id=\"T_54b88_row11_col5\" class=\"data row11 col5\" >68.77%</td>\n",
       "      <td id=\"T_54b88_row11_col6\" class=\"data row11 col6\" >74.75%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_54b88_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_54b88_row12_col0\" class=\"data row12 col0\" >request to speak to dbs</td>\n",
       "      <td id=\"T_54b88_row12_col1\" class=\"data row12 col1\" >67</td>\n",
       "      <td id=\"T_54b88_row12_col2\" class=\"data row12 col2\" >83.58%</td>\n",
       "      <td id=\"T_54b88_row12_col3\" class=\"data row12 col3\" >50.45%</td>\n",
       "      <td id=\"T_54b88_row12_col4\" class=\"data row12 col4\" >83.58%</td>\n",
       "      <td id=\"T_54b88_row12_col5\" class=\"data row12 col5\" >62.92%</td>\n",
       "      <td id=\"T_54b88_row12_col6\" class=\"data row12 col6\" >71.55%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_54b88_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_54b88_row13_col0\" class=\"data row13 col0\" >MACRO</td>\n",
       "      <td id=\"T_54b88_row13_col1\" class=\"data row13 col1\" >13,977</td>\n",
       "      <td id=\"T_54b88_row13_col2\" class=\"data row13 col2\" >72.95%</td>\n",
       "      <td id=\"T_54b88_row13_col3\" class=\"data row13 col3\" >64.90%</td>\n",
       "      <td id=\"T_54b88_row13_col4\" class=\"data row13 col4\" >72.95%</td>\n",
       "      <td id=\"T_54b88_row13_col5\" class=\"data row13 col5\" >68.05%</td>\n",
       "      <td id=\"T_54b88_row13_col6\" class=\"data row13 col6\" >72.41%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_54b88_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_54b88_row14_col0\" class=\"data row14 col0\" >MICRO</td>\n",
       "      <td id=\"T_54b88_row14_col1\" class=\"data row14 col1\" >13,977</td>\n",
       "      <td id=\"T_54b88_row14_col2\" class=\"data row14 col2\" >86.37%</td>\n",
       "      <td id=\"T_54b88_row14_col3\" class=\"data row14 col3\" >86.37%</td>\n",
       "      <td id=\"T_54b88_row14_col4\" class=\"data row14 col4\" >86.37%</td>\n",
       "      <td id=\"T_54b88_row14_col5\" class=\"data row14 col5\" >86.37%</td>\n",
       "      <td id=\"T_54b88_row14_col6\" class=\"data row14 col6\" >93.93%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_54b88_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_54b88_row15_col0\" class=\"data row15 col0\" >WEIGHT</td>\n",
       "      <td id=\"T_54b88_row15_col1\" class=\"data row15 col1\" >13,977</td>\n",
       "      <td id=\"T_54b88_row15_col2\" class=\"data row15 col2\" >86.37%</td>\n",
       "      <td id=\"T_54b88_row15_col3\" class=\"data row15 col3\" >87.48%</td>\n",
       "      <td id=\"T_54b88_row15_col4\" class=\"data row15 col4\" >86.37%</td>\n",
       "      <td id=\"T_54b88_row15_col5\" class=\"data row15 col5\" >86.75%</td>\n",
       "      <td id=\"T_54b88_row15_col6\" class=\"data row15 col6\" >90.40%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fc0e6db97f0>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if args.is_train_inference:\n",
    "    y_pred, y_target, losses_tmp=utils.eval_func(train_dataloader,model,device,num_classes=num_classes,loss_weight=loss_weight)\n",
    "    label_map={v:k for k,v in train_label_map.items()}\n",
    "else:\n",
    "    y_pred, y_target, losses_tmp=utils.eval_func(test_dataloader,model,device,num_classes=num_classes,loss_weight=loss_weight)\n",
    "    label_map={v:k for k,v in test_label_map.items()}\n",
    "\n",
    "print()\n",
    "print(label_map)\n",
    "print()\n",
    "\n",
    "n_classes=len(label_map)\n",
    "\n",
    "metrics_dict, acc, roc_auc, pr_auc = model_evaluate(y_target,y_pred)\n",
    "report=metrics.classification_report(y_target.squeeze(), y_pred.argmax(axis=1), output_dict=True)\n",
    "\n",
    "table = pd.DataFrame(report).transpose().iloc[:n_classes,:]\n",
    "table[\"count\"]=table[\"support\"].astype(int)\n",
    "table[\"accuracy\"]=[acc[i] for i in range(n_classes)]\n",
    "# table[\"roc_auc\"]=[roc_auc[i] for i in range(n_classes)]\n",
    "table[\"pr_auc\"]=[pr_auc[i] for i in range(n_classes)]\n",
    "table[\"subtype_type\"]=[label_map[i] for i in range(n_classes)]\n",
    "table=table[['subtype_type','count','accuracy','precision','recall','f1-score','pr_auc']]\n",
    "\n",
    "total=table['count'].sum()\n",
    "\n",
    "table.loc[len(table.index)]=[\"MACRO\",total,metrics_dict['acc_macro'],metrics_dict['prec_macro'],metrics_dict['recall_macro'],metrics_dict['fscore_macro'],metrics_dict['pr_auc_macro']]\n",
    "\n",
    "table.loc[len(table.index)]=[\"MICRO\",total,metrics_dict['acc_micro'],metrics_dict['prec_micro'],metrics_dict['recall_micro'],metrics_dict['fscore_micro'],metrics_dict['pr_auc_micro']]\n",
    "\n",
    "table.loc[len(table.index)]=[\"WEIGHT\",total,metrics_dict['acc_weighted'],metrics_dict['prec_weighted'],metrics_dict['recall_weighted'],metrics_dict['fscore_weighted'],metrics_dict['pr_auc_weighted']]\n",
    "\n",
    "table.style.format({\"count\":\"{:,}\",\"accuracy\":\"{:.2%}\",\"f1-score\":\"{:.2%}\",\"precision\":\"{:.2%}\",\"recall\":\"{:.2%}\",\"pr_auc\":\"{:.2%}\"})\n",
    "\n",
    "# print()\n",
    "# print(\"{:<20}{:<10.2%}\".format(\"accuracy\", metrics_dict['acc']))\n",
    "# print()\n",
    "# print(\"{:<20}{:<10,.2%}{:<16}{:<10,.2%}{:<18}{:<10,.2%}{:<17}{:<10,.2%}{:<16}{:<10,.2%}\"\\\n",
    "#       .format(\"precision(macro):\",metrics_dict['prec_macro'],\"recall(macro):\",metrics_dict['recall_macro'],\\\n",
    "#               \"f1-score(macro):\",metrics_dict['fscore_macro'],\"ROC-AUC(macro):\",metrics_dict['auc_macro_ovo'],\\\n",
    "#              \"PR-AUC(macro):\",metrics_dict['pr_auc_macro']))\n",
    "\n",
    "# print(\"{:<20}{:<10,.2%}{:<16}{:<10,.2%}{:<18}{:<10,.2%}{:<17}{:<10,.2%}{:<16}{:<10,.2%}\"\\\n",
    "#       .format(\"precision(micro):\",metrics_dict['prec_micro'],\"recall(micro):\",metrics_dict['recall_micro'],\\\n",
    "#               \"f1-score(micro):\",metrics_dict['fscore_micro'],\"ROC-AUC(micro):\",metrics_dict['auc_micro'],\\\n",
    "#              \"PR-AUC(micro):\",metrics_dict['pr_auc_micro']))\n",
    "\n",
    "# print(\"{:<20}{:<10,.2%}{:<16}{:<10,.2%}{:<18}{:<10,.2%}{:<17}{:<10,.2%}{:<16}{:<10,.2%}\"\\\n",
    "#       .format(\"precision(weight):\",metrics_dict['prec_weighted'],\"recall(weight):\",metrics_dict['recall_weighted'],\\\n",
    "#               \"f1-score(weight):\",metrics_dict['fscore_weighted'],\"ROC-AUC(weight):\",metrics_dict['auc_weighted_ovo'],\\\n",
    "#              \"PR-AUC(weight):\",metrics_dict['pr_auc_weighted']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9a26dd38-b9a7-4e99-a4d6-d0d0a339854e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print()\n",
    "# print(label_map)\n",
    "\n",
    "# n_classes=len(label_map)\n",
    "\n",
    "# report=metrics.classification_report(y_target.squeeze(), y_pred.argmax(axis=1), output_dict=True)\n",
    "\n",
    "# table = pd.DataFrame(report).transpose().iloc[:n_classes,:]\n",
    "# table[\"count\"]=table[\"support\"].astype(int)\n",
    "# table[\"roc_auc\"]=[roc_auc[i] for i in range(n_classes)]\n",
    "# table[\"pr_auc\"]=[pr_auc[i] for i in range(n_classes)]\n",
    "# table[\"subtype_type\"]=[label_map[i] for i in range(n_classes)]\n",
    "# table=table[['subtype_type','count','precision','recall','f1-score','roc_auc','pr_auc']]\n",
    "\n",
    "# total=table['count'].sum()\n",
    "\n",
    "# table.loc[len(table.index)]=[\"MACRO\",total,metrics_dict['prec_macro'],metrics_dict['recall_macro'],metrics_dict['fscore_macro'],\\\n",
    "#                         metrics_dict['auc_macro_ovo'],metrics_dict['pr_auc_macro']]\n",
    "\n",
    "# table.loc[len(table.index)]=[\"MICRO\",total,metrics_dict['prec_micro'],metrics_dict['recall_micro'],metrics_dict['fscore_micro'],\\\n",
    "#                             metrics_dict['auc_micro'],metrics_dict['pr_auc_micro']]\n",
    "\n",
    "# table.loc[len(table.index)]=[\"WEIGHT\",total,metrics_dict['prec_weighted'],metrics_dict['recall_weighted'],metrics_dict['fscore_weighted'],\\\n",
    "#                         metrics_dict['auc_weighted_ovo'],metrics_dict['pr_auc_weighted']]\n",
    "\n",
    "# table.style.format({\"count\":\"{:,}\",\"f1-score\":\"{:.2%}\",\"precision\":\"{:.2%}\",\"recall\":\"{:.2%}\",\"roc_auc\":\"{:.2%}\",\"pr_auc\":\"{:.2%}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d3f620-84c4-409c-97aa-a88bca36f411",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d2a4f3e2-7e80-4d64-91a2-fc85b72024c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def metric_table(table_name=\"metrics_training.txt\"):\n",
    "#     Model_Type=[]\n",
    "#     EPOCH=[]\n",
    "#     LOSS=[]\n",
    "#     Accuracy=[]\n",
    "#     False_Prediction=[]\n",
    "#     Accuracy=[]\n",
    "#     fscore_micro=[]\n",
    "#     fscore_macro=[]\n",
    "#     fscore_weighted=[]\n",
    "#     auc_micro=[]\n",
    "#     auc_macro=[]\n",
    "#     auc_weighted=[]\n",
    "\n",
    "#     with open(os.path.join(os.getcwd(),table_name),'r') as f:\n",
    "#         for line in f:\n",
    "#             Model_Type.append(str(line.split(\",\")[0]))\n",
    "#             EPOCH.append(int(line.split(\",\")[1]))\n",
    "#             LOSS.append(float(line.split(\",\")[2]))\n",
    "#             Accuracy.append(float(line.split(\",\")[3]))\n",
    "#             fscore_micro.append(float(line.split(\",\")[4]))\n",
    "#             fscore_macro.append(float(line.split(\",\")[5]))\n",
    "#             fscore_weighted.append(float(line.split(\",\")[6]))\n",
    "#             auc_micro.append(float(line.split(\",\")[7]))\n",
    "#             auc_macro.append(float(line.split(\",\")[8]))\n",
    "#             auc_weighted.append(float(line.split(\",\")[9]))\n",
    "\n",
    "\n",
    "#     metrics=pd.DataFrame({\"model_type\":Model_Type,\"epoch\":EPOCH,\"loss\":LOSS,\"Accuracy\":Accuracy,\"F1-Score-Micro\":fscore_micro,\"F1-Score-Macro\":fscore_macro,\\\n",
    "#                          \"F1-Score-Weighted\":fscore_weighted,\"AUC_Micro\":auc_micro,\"AUC-Macro\":auc_macro,\"AUC-Weighted\":auc_weighted})\n",
    "#     metrics.drop_duplicates(subset=[\"model_type\",\"epoch\"],inplace=True)\n",
    "#     metrics.sort_values(by=['model_type','epoch'],inplace=True)       \n",
    "    \n",
    "#     return metrics\n",
    "\n",
    "# def style_format(metrics_training, metrics_test, model):\n",
    "#     metrics_training=metrics_training[metrics_training[\"model_type\"]==model].reset_index(drop=True)\n",
    "#     metrics_training=metrics_training.sort_values('F1-Score-Weighted', ascending=False).head(1)\n",
    "#     metrics_training.drop(\"epoch\",inplace=True,axis=1)\n",
    "#     metrics_training[\"data\"]=[\"training set\"]\n",
    "    \n",
    "#     metrics_test=metrics_test[metrics_test[\"model_type\"]==model].reset_index(drop=True)\n",
    "#     metrics_test=metrics_test.sort_values('F1-Score-Weighted', ascending=False).head(1)\n",
    "#     metrics_test.drop(\"epoch\",inplace=True,axis=1)\n",
    "#     metrics_test[\"data\"]=[\"test set\"]\n",
    "    \n",
    "#     metrics=pd.concat([metrics_training,metrics_test])\n",
    "#     first_column =  metrics.pop('data')\n",
    "#     metrics.insert(0, 'data', first_column)\n",
    "    \n",
    "#     return metrics.style.format({\"loss\":\"{:.4f}\",\"Accuracy\":\"{:.2%}\",\"F1-Score-Micro\":\"{:.2%}\",\"F1-Score-Macro\":\"{:.2%}\", \"F1-Score-Weighted\":\"{:.2%}\", \"AUC_Micro\":\"{:.2%}\", \\\n",
    "#                                 \"AUC-Macro\":\"{:.2%}\", \"AUC-Weighted\":\"{:.2%}\"}) \\\n",
    "#     .set_caption(f\"Performance Summary for-- {model}\") \\\n",
    "#     .set_table_styles([{\n",
    "#         'selector': 'caption',\n",
    "#         'props': [\n",
    "#             ('color', 'red'),\n",
    "#             ('font-size', '20px')\n",
    "#         ]\n",
    "#     }])\n",
    "\n",
    "# metric_training=metric_table(table_name=\"metrics_training.txt\")\n",
    "# metric_test=metric_table(table_name=\"metrics_test.txt\")\n",
    "\n",
    "# # style_format(metric_training,metric_test, model=\"bert_base\")\n",
    "\n",
    "# style_format(metric_training,metric_test, model=\"bert_large\")\n",
    "\n",
    "# # style_format(metric_training,metric_test, model=\"roberta_base\")\n",
    "\n",
    "# style_format(metric_training,metric_test, model=\"roberta_large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf6340f-e177-4cac-910c-01625c8d1d29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fe7e48-f4c5-4114-85a2-919a1d298c41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
