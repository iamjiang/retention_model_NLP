{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "506db261-7954-4f55-a7c7-82747916a87f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/test/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(position=0,leave=True)\n",
    "import textwrap\n",
    "import random\n",
    "import time \n",
    "\n",
    "from transformers import AutoModelForMaskedLM , AutoTokenizer\n",
    "import torch\n",
    "from NLP_prompt import Prompting\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41225ed7-cd04-4cb2-b7d2-c7fd7142b53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 28.0/28.0 [00:00<00:00, 52.9kB/s]\n",
      "Downloading: 100%|██████████| 571/571 [00:00<00:00, 1.06MB/s]\n",
      "Downloading: 100%|██████████| 226k/226k [00:00<00:00, 55.9MB/s]\n",
      "Downloading: 100%|██████████| 455k/455k [00:00<00:00, 83.4MB/s]\n",
      "Downloading: 100%|██████████| 1.25G/1.25G [00:11<00:00, 120MB/s]\n",
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'prompt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# load Prompting class\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprompt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Prompting\n\u001b[0;32m----> 6\u001b[0m prompting\u001b[38;5;241m=\u001b[39m Prompting(model\u001b[38;5;241m=\u001b[39mmodel_path)\n",
      "File \u001b[0;32m~/SageMaker/retention_model_NLP/prompt_negativity/prompt.py:29\u001b[0m, in \u001b[0;36mPrompting.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m AutoModelForMaskedLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_path)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(tokenizer_path)\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprompt\u001b[38;5;241m=\u001b[39m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'prompt'"
     ]
    }
   ],
   "source": [
    "model_path=\"bert-large-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# load Prompting class\n",
    "from prompt import Prompting\n",
    "prompting= Prompting(model=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84bd18a5-99df-43af-8097-83e86f57953e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It takes 235.4136 seconds to read the data\n"
     ]
    }
   ],
   "source": [
    "input_dir=\"s3://trident-retention-output/\"\n",
    "output_dir=\"s3://trident-retention-output/output/\"\n",
    "\n",
    "start=time.time()\n",
    "df=pd.read_pickle(os.path.join(output_dir,\"askunum_text_bagofword\"))\n",
    "end=time.time()\n",
    "print(\"It takes {:.4f} seconds to read the data\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1d8f774-0f44-4df2-a516-8392d406a15c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ParentId</th>\n",
       "      <th>Subtype</th>\n",
       "      <th>TextBody</th>\n",
       "      <th>bag_of_word</th>\n",
       "      <th>negative_word_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5000c00001TWN6bAAH</td>\n",
       "      <td>employee coding</td>\n",
       "      <td>unum, the following associates have been termi...</td>\n",
       "      <td>following associates terminated company listed...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5000c00001TWN9pAAH</td>\n",
       "      <td>tax question</td>\n",
       "      <td>who pays the futa and sui taxes? do you odo we...</td>\n",
       "      <td>pays futa sui taxes odo report pay collect pay...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ParentId          Subtype  \\\n",
       "0  5000c00001TWN6bAAH  employee coding   \n",
       "1  5000c00001TWN9pAAH     tax question   \n",
       "\n",
       "                                            TextBody  \\\n",
       "0  unum, the following associates have been termi...   \n",
       "1  who pays the futa and sui taxes? do you odo we...   \n",
       "\n",
       "                                         bag_of_word  negative_word_counts  \n",
       "0  following associates terminated company listed...                     6  \n",
       "1  pays futa sui taxes odo report pay collect pay...                    14  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96343aba-b0b9-41a0-b145-0bd9f8d35fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********************************************************************************\n",
      "*  Full TextBody :   subtype=additional claim information received *\n",
      "********************************************************************************\n",
      "\n",
      "please see attached focourtney vandenberg, claim numbe. thank you, jessica steele hmanagebig riveresources, llc 211 north geasuite200, west\n",
      "burlington, ia 52655 main 319-753-1100 direct 319-754-2106 fax 866.497.4190 what lies behind you and what lies in front of you, pales in comparison to\n",
      "what lies within you. hello jessica, . i have provided the attached information focourtney to ouclaim team. if additional information is required,\n",
      "theiclaim specialist will follow up. did you know you can reach oubenefits department directly with questions, fostatus updates oto submit additional\n",
      "claims documents at telephone 800-858-6843 secufax 800-447-2498 email must include claim 18403832 in the subject line. please send one email\n",
      "peclaimant. benefits is unable to accept multiple documents fodifferent claimants in one email. please let us know if theis anything furthewe may\n",
      "assist you with. thank you, andrew mackeil service specialist ii he/him/his unum client service cente-800-ask-unum 1-800-275-8686 askunumunum.com .\n",
      "\n",
      "**************************************************\n",
      "\n",
      "********************************************************************************\n",
      "*  Full TextBody :   subtype=payment status *\n",
      "********************************************************************************\n",
      "\n",
      "can you confirm if we have any premium in house fothe above group that has not been applied? it does not look like it has posted yet scott kugleunum l\n",
      "seniosales consultant 2505 east paris ave suite 125 grand rapids, mi 49546 phone 248 351-1613 cell 248 417-5544 unum by the numbers 1 in group\n",
      "individual disability 2 in voluntary benefits group life hello scott, thank you foreaching out. we anot showing we have received the payment. if the\n",
      "check has been cashed, we can research this furthewith the check numbecashed date and amount. the group may call into outeam at 1-800-ask-unum\n",
      "1-800-275-8686 and we can take a payment ovethe phone. we will need the following information routing numbeaccount numbecheck numbeamount please let\n",
      "us know if theis anything else we can assist with. we ahappy to help thank you, kate thibodeau service specialist unum client service cente-800-ask-\n",
      "unum 1-800-275-8686 askunumunum.com . , . ---------------\n",
      "\n",
      "**************************************************\n",
      "\n",
      "********************************************************************************\n",
      "*  Full TextBody :   subtype=missing information *\n",
      "********************************************************************************\n",
      "\n",
      "michael sepe applied on line through oubenefits platform beacon benefit solution. second harvest food bank hello larnise , thank you foproviding the\n",
      "details. we aworking to process the enrollment. approved changes will reflect on a futubilling statement. we hope this information is helpful. please\n",
      "do not hesitate to let us know if theis anything furthewe may assist you with. foinformation and resources regarding unum's covid-19 response and\n",
      "faqs, visit unum.com/covid-19 thank you, the ask unum team client success organization 1-800-ask-unum 1-800-275-8686\n",
      "\n",
      "**************************************************\n",
      "\n",
      "********************************************************************************\n",
      "*  Full TextBody :   subtype=add, remove, or update user access *\n",
      "********************************************************************************\n",
      "\n",
      "hi see below o +1 917 639 3966 c +1 646 866 0334 -001 hello martina, thank you fothe email i have updated youaccess and removed enrico if you have any\n",
      "furthequestions please let us know thank you, haley hammeclient experience rep i client success organization 1-800-ask-unum 1-800-275-8686\n",
      "askunumunum.com unum covid-19 response - how to file a claim online - . , .\n",
      "\n",
      "**************************************************\n",
      "\n",
      "********************************************************************************\n",
      "*  Full TextBody :   subtype=dental or vision id card *\n",
      "********************************************************************************\n",
      "\n",
      "could you please send me an id card foisrael jalomo? katie green benefits service advisowatkins insurance group tel 512.276.5287 fax 512.452.0999 3834\n",
      "spicewood springs rd, suite 100 austin tx 78759 please note due to the increased volume of workload during oubusiest time of yeathat you may see\n",
      "longeresponse times. i appreciate youpatience and youbusiness. confidentiality notice the information contained in this electronic mail is privileged\n",
      "and confidential and is intended fothe use of the individual oentity named above. if the readeof this message is not the intended recipient, you\n",
      "ahereby notified that any dissemination, distribution ocopying of this electronic mail is strictly prohibited. if you have received this electronic\n",
      "mail in erroplease notify the sendeimmediately and delete all copies. hi team, due to online website issues, please assist with providing a pdf copy\n",
      "of the dental id card foisreal jalom 644-24-9343. thank you, beth davis service specialist client success organization 1-800-ask-unum 1-800-275-8686\n",
      "askunumunum.com . , . --------------- hi katie, thank you foyouresponse. we apartnering with youdental vision team to complete yourequest. we will be\n",
      "in contact with you shortly with the requested id card foisreal jalomo. if theis anything else we can help you with, please let us know. thank you,\n",
      "beth davis service specialist client success organization 1-800-ask-unum 1-800-275-8686 askunumunum.com unum covid-19 response - how to file a claim\n",
      "online - . , . this is a migrated policy. would you be able to assist in pulling a pdf id card fothe membelisted below please? 0444134 isreal jalom\n",
      "644-24-9343 thank you, brandalyn lancasteseniobusiness specialist 423 294-7593 blancasterunum.com foinformation and resources regarding unum's\n",
      "covid-19 response and faqs, visit unum.com/covid-19 ----- good afternoon au, i hope you awell . we ahappy to assist as requested, attached is the id\n",
      "card foisreal jalomo membeid 2855825. i am always happy to respond to the customebut since they aon the unum side, i thought it would be moencouraging\n",
      "fothe custometo utilize au if you responded with the id card. please let us know if you have any questions orequifurtheassistance. thank you\n",
      "foallowing us to be of service. it has been my pleasuto assist you best wishes, caryn lynn dental vision field support specialist dvfs phone\n",
      "225-201-7362 ----- -----\n",
      "\n",
      "**************************************************\n",
      "\n",
      "********************************************************************************\n",
      "*  Full TextBody :   subtype=policy termination *\n",
      "********************************************************************************\n",
      "\n",
      "good morning this is in reference o probaris 416965 please see attached term lettefothe group effective 3/31/2021 please confirm once completed,\n",
      "thanks thanks in advance tricia hasson market analyst kistletiffany / one digital company 413 marlton pike east suite 300 cherry hill, nj 08034\n",
      "direct- 856-672-6053 office- 856-427-9300 ext 36 fax- 856-672-6072 . disclaimethe information contained in this communication from the sendeis\n",
      "confidential. it is intended solely fouse by the recipient and others authorized to receive it. if you anot the recipient, you ahereby notified that\n",
      "any disclosucopying, distribution otaking action in relation of the contents of this information is strictly prohibited and may be unlawful. this\n",
      "email has been scanned foviruses and malwaand may have been automatically archived by mimecast ltd, an innovatoin softwaas a service saas fobusiness.\n",
      "providing a safeand mouseful place foyouhuman generated data. specializing in; security, archiving and compliance. good afternoon tricia, we have\n",
      "provided this policy termination letteto the groups local sales office foprocessing. please let us know if theis anything else we can assist you with.\n",
      "thank you, chris dube service specialist client success organization 1-800-ask-unum 1-800-275-8686 askunumunum.com unum covid-19 response - how to\n",
      "file a claim online - . , . 416965 hi, please see attached policy termination letter. thank you, chris dube service specialist client success\n",
      "organization 1-800-ask-unum 1-800-275-8686\n",
      "\n",
      "**************************************************\n",
      "\n",
      "********************************************************************************\n",
      "*  Full TextBody :   subtype=employee coding *\n",
      "********************************************************************************\n",
      "\n",
      "yes please call the dentists to confirm coverage fodeanna becker. burch dental 815-633-9864 coverage fodeanna beckebirth date jan 24, 1963 also\n",
      "camelot endodontics 815-636-1600 ryan kraft assurance account manageeast golf road schaumburg, il 60173 p follow us on twittelinkedin facebook youtube\n",
      "hello team, please do a call out fothe spouse of employee ee robert becke-48-5306. the dentist and spouse information is below. thank you, jason\n",
      "ziegleservice specialist unum client service cente-800-ask-unum 1-800-275-8686 hello ryan, i have requested a call out to the dentists this morning.\n",
      "if theis any problem, oif any otheinformation is needed, someone will contact you. thank you, jason ziegleservice specialist unum client service\n",
      "cente-800-ask-unum 1-800-275-8686 thanks please let me know when the calls have been made. ryan kraft assurance account manageeast golf road\n",
      "schaumburg, il 60173 p follow us on twittelinkedin facebook youtube hi jason - the membeand spouse have successfully passed to starmount. i have\n",
      "attached the id card. jacob davis seniobusiness specialist unum dental operations phone 423-294-9008 jdavis4unum.com ----- ----- hello ask unum, cobra\n",
      "memberobert beckeand his wife aagain being told by theidental providers that they have not had coverage since 2/1/19. pethe email thread below, i\n",
      "thought this was resolved months ago. can you please advise why theicoverage is inactive again? thanks, ryan kraft assurance account manageeast golf\n",
      "road schaumburg, il 60173 p 847.463.7851 follow us on twittelinkedin facebook youtube\n",
      "\n",
      "**************************************************\n",
      "\n",
      "********************************************************************************\n",
      "*  Full TextBody :   subtype=renewal inquiry *\n",
      "********************************************************************************\n",
      "\n",
      "will you please provide renewal updates fok v construction and koch facial plastic surgery? laura eisenman case coordinatobenefit source, inc. 4000\n",
      "westown pkwy, ste. 110 west des moines, ia 50266 ph 515.453.9462 ext. 18 fx 515.453.9472 this electronic mail transmission, including attachments, may\n",
      "contain information from benefit source, inc. that is privileged, confidential oproprietary and may be subject to protection undethe law, including\n",
      "the health insurance portability accountability act hipaa. this information is solely fothe intended recipients. if you anot the intended recipient,\n",
      "you anotified that any use, disclosucopying, odistribution of this message oattachment is strictly prohibited. if you have received this email in\n",
      "erroplease contact the sendeimmediately by replying to this email and delete this material from any computer. we apartnering with the renewal area to\n",
      "assist with this request. a membeof the team will be reaching out as soon as possible. in the meantime. have a great day thank you, cameron ray\n",
      "service specialist unum client service cente-800-ask-unum 1-800-275-8686 hi team, please process the below request fothe renewals. i have attached a\n",
      "copy of the invoices. thank you, cameron ray service specialist unum client service cente-800-ask-unum 1-800-275-8686 askunumunum.com . , .\n",
      "---------------\n",
      "\n",
      "**************************************************\n",
      "\n",
      "********************************************************************************\n",
      "*  Full TextBody :   subtype=enrollment submission *\n",
      "********************************************************************************\n",
      "\n",
      "heffernan insurance brokers - ca insurance license 0564249 this communication, including attachments, is fothe exclusive use of addressee and may\n",
      "contain proprietary oconfidential information. if you anot the intended recipient, any use, copying, disclosudissemination odistribution is strictly\n",
      "prohibited. if you anot the intended recipient, please notify the sendeimmediately by return email and delete this communication and destroy all\n",
      "copies. please note, any request to bind coverage, modify coverage oreport a claim is not valid until you receive confirmation from heffernan\n",
      "insurance brokers that we have processed yourequest. thank you, bridget casale service specialist unum client service cente-800-ask-unum\n",
      "1-800-275-8686 askunumunum.com . , . --------------- lewis llewellyn llp hi elisa, the enrollment form foamanda schwartz has been sent foprocessing.\n",
      "if additional information is required, a membeof the team will reach out to you. any approved changes will be reflected on a futubilling statement.\n",
      "please let us know if theis anything else that we could assist you with in the meantime. thank you, bridget casale service specialist ask unum\n",
      "1-800-ask-unum 1-800-275-8686 askunumunum.com . , . ---------------\n",
      "\n",
      "**************************************************\n",
      "\n",
      "********************************************************************************\n",
      "*  Full TextBody :   subtype=employee coding *\n",
      "********************************************************************************\n",
      "\n",
      "hello, hestart date fothe current location is 03/01/2022. thank you and hope you have a great day respectfully, april hollingsworth benefits\n",
      "specialist financial design group 11122 s. yale ave suite a tulsa, ok 74137 p 918-394-3900 f 918-394-4930 -0017-00013 hello april, . we would like to\n",
      "inform you that we checked ourecords and can confirm that patricia skagg showing enrolled in two division we would request you please suggest in which\n",
      "division you want a date correction. division 0017- terminated division 0013-active i hope this information is helpful. please do not hesitate to let\n",
      "us know if theis anything furthewe may assist you with. thank you, the ask unum team client success organization 1-800-ask-unum 1-800-275-8686\n",
      "askunumunum.com unum covid-19 response - how to file a claim online - . , . hello, she was moved to a new location, so we need the start date\n",
      "fowindsohills to be 03/01/2022. thank you and hope you have a great day respectfully, april hollingsworth benefits specialist financial design group\n",
      "11122 s. yale ave suite a tulsa, ok 74137 p 918-394-3900 f 918-394-4930\n",
      "\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "wrapper = textwrap.TextWrapper(width=150) \n",
    "# Randomly choose some examples.\n",
    "for i in range(10):\n",
    "    random.seed(101+i)\n",
    "\n",
    "    j = random.choice(df.index)\n",
    "    emails=df.loc[j,\"TextBody\"]\n",
    "    subtype=df.loc[j,\"Subtype\"]\n",
    "\n",
    "    print('')\n",
    "    print(\"*\"*80)\n",
    "    print(f'*  Full TextBody :   subtype={subtype} *')\n",
    "    print(\"*\"*80)\n",
    "    print('')\n",
    "    # print(j)\n",
    "    print(wrapper.fill(emails))\n",
    "    print('')\n",
    "    print(\"*\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283ff5ef-dc97-46d2-b6e7-9e6c51461eb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c756baeb-5b1a-4706-adcd-65a3d9932cb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8754, 0.1246])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt=\"It has [MASK] sentiment.\"\n",
    "prompting.compute_tokens_prob(prompt, token_list1=[\"positive\",\"neutral\"], token_list2= [\"negative\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dff5653-0c51-4595-bb50-423f34f7cda9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "055d1e36-c35b-4e28-a08e-8850132daf29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"unum, the following associates have been terminated from the company and should not be listed as covered undegerresheimeptc usa lp. dennis bussie 256-35-1645 jarrita blackmon 258-55-8371 thomas brindamou-38-5028 mark e dicicco 432-33-7949 jay fitzgerald 195-56-9599 ulysses gray 253-53-5846 georgia keith 260-13-7587 jeffrey knoblett 259-37-2420 termed 12/22/17 dana lowe 253-35-6109 warren morrow 417-98-8010 lex price 529-13-5634 domingues roberts termed 12/18/17 parwitasingelton termed 12/14/17 these individuals should have came oveon an electronic file as they wetermed in ousystem, and some of these individuals i termed in yousystem. good morning carla, please provide warren morrow's last day worked to process termination. all otheemployee's atermed as requested. please let us know if theis anything else we can assist you with in the meantime. thank you, juan gutierrez service specialist associate unum client service cente-800-ask-unum 1-800-275-8686\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0,\"TextBody\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bbd2f00-bad2-43eb-b2f1-a4a5495f5224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', tensor(10.4515)),\n",
       " ('the', tensor(9.8634)),\n",
       " ('no', tensor(9.5981)),\n",
       " ('another', tensor(8.9780)),\n",
       " ('been', tensor(8.9193)),\n",
       " ('your', tensor(8.9181)),\n",
       " ('great', tensor(8.7213)),\n",
       " ('my', tensor(8.6338)),\n",
       " ('this', tensor(8.5194)),\n",
       " ('that', tensor(8.2376))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=df.loc[0,\"TextBody\"]\n",
    "prompt=\"It has [MASK] sentiment.\"\n",
    "prompting.prompt_pred(text+prompt)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a0d9cbe-824d-47aa-9762-26a6ef21ed7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9600, 0.0400])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompting.compute_tokens_prob(text+prompt, token_list1=[\"positive\",\"neutral\"], token_list2= [\"negative\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb7cce0-bfd2-4169-a254-3da2789497cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "003159b8-56a5-4f02-9506-ed321ff53f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'who pays the futa and sui taxes? do you odo we need to report and pay those? i know you collect and pay the fica/medicare. patty lawson hmanaget 512-380-7108 f 512-459-1459 this communication and any files oattachments transmitted with it may contain information that is confidential, privileged and exempt from disclosuundeapplicable law. it is intended solely fothe use of the individual othe entity to which it is addressed. if you anot the intended recipient, you ahereby notified that any use, dissemination, ocopying of this communication is strictly prohibited. if you have received this communication in erroplease notify the sendeat once so that we may take the appropriate action. we aworking with outax unit on the request. they will be reaching out to you soon. please let us know if theis anything else we can assist with in the meantime. thank you, jessica brunhoebeservice specialist unum client service cente-800-ask-unum 1-800-275-8686 hello team i hope you awell please assist with the request below regarding employetaxes. thank you in advance foyouassistance thank you, jessica brunhoebeservice specialist unum client service cente-800-ask-unum 1-800-275-8686 the policyholdeis responsible foany applicable futa/suta thanks, nancy hookey trg'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[1,\"TextBody\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9f6b142-88c8-4a82-987d-74ccbb70f095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9790, 0.0210])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=df.loc[1,\"TextBody\"]\n",
    "prompt=\"It has [MASK] sentiment.\"\n",
    "prompting.compute_tokens_prob(text+prompt, token_list1=[\"positive\",\"neutral\"], token_list2= [\"negative\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16b978e-c24b-4204-a5bc-b8a77a8b8952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52676f27-4a24-4e04-8d3f-1b1df2dcc51d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ParentId</th>\n",
       "      <th>Subtype</th>\n",
       "      <th>TextBody</th>\n",
       "      <th>bag_of_word</th>\n",
       "      <th>negative_word_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5003x00002Eecc2AAB</td>\n",
       "      <td>ach inquiry or confirmation</td>\n",
       "      <td>clorox services company purchase ordeusa00152...</td>\n",
       "      <td>clorox services company purchase ordeusa power...</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5000c00001axMyiAAE</td>\n",
       "      <td>claim status</td>\n",
       "      <td>deasiomadame, i am writing on behalf of my mot...</td>\n",
       "      <td>deasiomadame writing behalf motheevereen daley...</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5000c00001cy4H8AAI</td>\n",
       "      <td>employee coding</td>\n",
       "      <td>good afternoon, could you please make suthe fo...</td>\n",
       "      <td>good afternoon suthe following employees anot ...</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5003x000024WTGOAA4</td>\n",
       "      <td>correspondence change</td>\n",
       "      <td>pejonathans request, we want to be suangie is ...</td>\n",
       "      <td>pejonathans request want suangie listed primar...</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5003x00002D7WDgAAN</td>\n",
       "      <td>claim status</td>\n",
       "      <td>louisiana department of insurance p.o. box 942...</td>\n",
       "      <td>louisiana department insurance p o box baton r...</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ParentId                      Subtype  \\\n",
       "0  5003x00002Eecc2AAB  ach inquiry or confirmation   \n",
       "1  5000c00001axMyiAAE                 claim status   \n",
       "2  5000c00001cy4H8AAI              employee coding   \n",
       "3  5003x000024WTGOAA4        correspondence change   \n",
       "4  5003x00002D7WDgAAN                 claim status   \n",
       "\n",
       "                                            TextBody  \\\n",
       "0   clorox services company purchase ordeusa00152...   \n",
       "1  deasiomadame, i am writing on behalf of my mot...   \n",
       "2  good afternoon, could you please make suthe fo...   \n",
       "3  pejonathans request, we want to be suangie is ...   \n",
       "4  louisiana department of insurance p.o. box 942...   \n",
       "\n",
       "                                         bag_of_word  negative_word_counts  \n",
       "0  clorox services company purchase ordeusa power...                   158  \n",
       "1  deasiomadame writing behalf motheevereen daley...                   101  \n",
       "2  good afternoon suthe following employees anot ...                    92  \n",
       "3  pejonathans request want suangie listed primar...                    88  \n",
       "4  louisiana department insurance p o box baton r...                    88  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(\"negative_word_counts\",ascending=False,inplace=True)\n",
    "df=df.reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "13df32bb-8ea9-40ad-aa29-691ef2a8fc8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"deasiomadame, i am writing on behalf of my motheevereen daley.i would like to update unum on my mothemedical conditions while she is awaiting foand still undergoing inpatient and outpatient medical treatment and care. i am unable to send this email and documentation via unum portal. she is stll in immediate need of home health caassistance with daily living and activity during the daytime, nighttime and weekend hours including skilled therapy services fophysical and occupational therapy foseven days a week. as you aalready awashe is not able to reach the bathroom in time, oforgetting whethe bathroom is. she use signage to point the way and have nightlights and emergency lights, have grab rails that she can use while reaching the bathroom, and already have clothing that can be taken off easily. she will have fecal and urinary incontinence accident in the bathroom but won't tell me about it so i won't know until i go in theand see the mess. hebrain is foggy so theis sign of dementia. she experiencing excruiating pain fodays straightbin left pelvic. aftedays of complete, uttepain and trying everything over-the-counteto appease it, she had to be rush into urgent cabecause the pain in helowebody feels like hehips and legs amade of cement, olike that part of hebody is rotting. that makes it a lot hardefoheto move around. she is experiencing difficulties walking, excessive heavy bleeding which required transfusion, deep vien blood clot, shortness of breathe, heart palpitations, difficulty maintaining balance and occasional falls related to vertigo, sudden sensation that the room is spinning owhirling when she is moving, sitting ostanding still and sevemobility impairments on heright side of hebody. hechronic sevepain that radiates to the right side, including the right shouldeblade. stiffness in the morning that gets betteduring the day, but begins to ache in the evening. difficulty using right hand/fingers and right foot/toes including burning, tingling, and numbness. pain in the right shouldegoes down the arm to the elbow and hand sensation that the hand is swollen. weakened grip and difficulty picking up small items. swelling and tenderness at the base of the thumb and ankle. problems with fine fingemovements in right hands. there's pain when she lowehebody and shouldefrom a raised position. doing any kinds of movements every day oputting stress on joints increases the pain foboth conditions such as reaching, pushing, pulling, olifting the arm above shouldelevel can make the pain worse. even lying on the painful side can worsen the problem and she has been awaken sufferers at night.she also feel ringing and pressuin the right eaintense dizzy, lightheaded, ohad to focus, frequent headaches omigraines, nausea increases when dizziness get worse, she have bruised areas on loweextremities from falls and sprain right foot. she has a history of nausea, vomiting, diarrhea, chronic fatigue, feaanxiety, opanic depression. sweatingband unable to maintain medication due to nausea. basically she is limited and only getting up with my assistance and hecane even with modified bathroom and medical supply. she still recieved in-home aides services plan of service which has been approved of personal caservice hours foadditional 26 hours to assist with feeding and hefood is cut into in smallesizes, feeding assistance using a towel obib to protect clothing and bedding, help hesit in a straight so the she does have to stretch to eat, dressing hand hethe clothes, socks and shoes, brushing heteeth, supervise transfers uses cane, supervise ambulation uses cane, bathing with supervision, toileting, grooming, meal preparation, set up and clean up, housekeeping, laundry, shopping, medication reminders and accompany fotravel. due to herniated raptudisc she is at risk of falling, injuring heneck and back i transferred hefromseated to standing and getting in and out of bed ocar. she cannot be left alone and need constant cabecause of wandering risks and actions that has been harmful odangerous such as leaving cooking burners on in the past and falling. i accommodate hedaily with getting heout of bed and chaiassistance with bathing, in ordeto stay to sitting osquatting while using the toilet, lift up heleg to put on and removing diapers, in ordeto undo zippefovisits outside, diapers is the only option. hold spoon and bringing it to the mouth without spilling food, assistance with medication, washing haishopping, transportation to and from doctoappointment, daily chores; light correspondence; equipment cleaning; and emergency procedures, maintain a list of emergency numbers and monitoring of self-medication. basic reading, writing, and simple counting has becomes increasingly difficult and consists moof using electronical devices. while she's still on the prescribed medications oxycodone, percot, hydrocodone w/acetaminophen flexeril, fioceret, odt, promethazine hcl 12.5 mg oral tablet, xanax and xalreto some side effects of prescription arisk of stroke, heart disease, inflammation, changes in blood glucose, heavy bleeding, mental fatigue, anemia, dry mouth othroat; blurred vision; sevedrowsiness, dizziness, tired feeling; and occasional loss of appetite, stomach pain, nausea; diarrhea, constipation, and gas. also, heis a list following medical supply she utilized reachehand held sponge elastic shoe laces black x 2 paifeeding equipment built up spoon/fork/knife 1 each partitioned plate. sock aide bathroom equipment non skidding mat showechaiwith back toilet railings rolling showechaiand transport wheelchair. last with reference to above, please find attached herewith plan of service cain reference to heservice fodisabling chronic diseases that aa significant burden including hospitalization and continue changes in hemedical condition and functioning status thanks foreading this letter. i can be reached by email oby telephone at 301 o-2039. / evereen daley, 578-88-2640 / claim 9480832 hi lisa,please review the email below related to this claim and reply as needed. thank you, kenneth galvani service specialist unum client service cente-800-ask-unum 1-800-275-8686 askunumunum.com . , . --------------- thank you, information has been imaged to the claim file.\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=df.loc[1,\"TextBody\"]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff8b8f2b-af99-491c-be92-135bbdc750e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (1454) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 1454].  Tensor sizes: [1, 512]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [28], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m text\u001b[38;5;241m=\u001b[39mdf\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTextBody\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      2\u001b[0m prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt has [MASK] sentiment.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m prompting\u001b[38;5;241m.\u001b[39mcompute_tokens_prob(text\u001b[38;5;241m+\u001b[39mprompt, token_list1\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositive\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneutral\u001b[39m\u001b[38;5;124m\"\u001b[39m], token_list2\u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnegative\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/SageMaker/retention_model_NLP/prompt_negativity/prompt.py:78\u001b[0m, in \u001b[0;36mPrompting.compute_tokens_prob\u001b[0;34m(self, text, token_list1, token_list2)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_tokens_prob\u001b[39m(\u001b[38;5;28mself\u001b[39m, text, token_list1, token_list2):\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;124;03m    Compute the activations for given two token list, \u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;124;03m    Parameters:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;124;03m       )\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m     _\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprompt_pred\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m     score1\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscores_dict[token1] \u001b[38;5;28;01mif\u001b[39;00m token1 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscores_dict\u001b[38;5;241m.\u001b[39mkeys() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\\\n\u001b[1;32m     80\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m token1 \u001b[38;5;129;01min\u001b[39;00m token_list1]\n\u001b[1;32m     81\u001b[0m     score1\u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(score1)\n",
      "File \u001b[0;32m~/SageMaker/retention_model_NLP/prompt_negativity/prompt.py:52\u001b[0m, in \u001b[0;36mPrompting.prompt_pred\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 52\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexed_tokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     54\u001b[0m values, indices\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39msort(predictions[\u001b[38;5;241m0\u001b[39m, mask_pos],  descending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:1350\u001b[0m, in \u001b[0;36mBertForMaskedLM.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1341\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1342\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1343\u001b[0m \u001b[38;5;124;03m    Labels for computing the masked language modeling loss. Indices should be in `[-100, 0, ...,\u001b[39;00m\n\u001b[1;32m   1344\u001b[0m \u001b[38;5;124;03m    config.vocab_size]` (see `input_ids` docstring) Tokens with indices set to `-100` are ignored (masked), the\u001b[39;00m\n\u001b[1;32m   1345\u001b[0m \u001b[38;5;124;03m    loss is only computed for the tokens with labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1348\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1350\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1351\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1352\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1356\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1359\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1360\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1361\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1362\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1364\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1365\u001b[0m prediction_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcls(sequence_output)\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:983\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    981\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    982\u001b[0m     buffered_token_type_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings\u001b[38;5;241m.\u001b[39mtoken_type_ids[:, :seq_length]\n\u001b[0;32m--> 983\u001b[0m     buffered_token_type_ids_expanded \u001b[38;5;241m=\u001b[39m \u001b[43mbuffered_token_type_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    984\u001b[0m     token_type_ids \u001b[38;5;241m=\u001b[39m buffered_token_type_ids_expanded\n\u001b[1;32m    985\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (1454) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 1454].  Tensor sizes: [1, 512]"
     ]
    }
   ],
   "source": [
    "text=df.loc[1,\"TextBody\"]\n",
    "prompt=\"It has [MASK] sentiment.\"\n",
    "prompting.compute_tokens_prob(text+prompt, token_list1=[\"positive\",\"neutral\"], token_list2= [\"negative\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3b30256f-fcd4-4b53-8488-b86d5188b742",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=df.loc[1,\"TextBody\"]\n",
    "prompt=\"It has [MASK] sentiment.\"\n",
    "text=text+prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead16108-4a25-428b-8595-896436eb3f44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7a3d898c-4df1-404b-99a4-451873451460",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_path=\"bert-large-uncased\"\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6ce105bb-23ed-4769-bb5a-e0e82a642b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_len=len(tokenizer(prompt,add_special_tokens=False).input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "707f1f49-8631-4850-9e8e-a29b5c8acb1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'[MASK]' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [41], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m tokenized_text\u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mconvert_ids_to_tokens (indexed_tokens[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# take the first masked token\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m mask_pos\u001b[38;5;241m=\u001b[39mtokenized_text\u001b[38;5;241m.\u001b[39mindex(tokenizer\u001b[38;5;241m.\u001b[39mmask_token)\n",
      "\u001b[0;31mValueError\u001b[0m: '[MASK]' is not in list"
     ]
    }
   ],
   "source": [
    "\n",
    "indexed_tokens=tokenizer(text, return_tensors=\"pt\",max_length=512-2-prompt_len).input_ids\n",
    "tokenized_text= tokenizer.convert_ids_to_tokens(indexed_tokens[0])\n",
    "# take the first masked token\n",
    "mask_pos=tokenized_text.index(tokenizer.mask_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "429c39ad-5d1c-40ec-bb0d-23f8fa05d56a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (1454) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 1454].  Tensor sizes: [1, 512]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [36], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 3\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(indexed_tokens)\n\u001b[1;32m      4\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      5\u001b[0m values, indices\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39msort(predictions[\u001b[38;5;241m0\u001b[39m, mask_pos],  descending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:1350\u001b[0m, in \u001b[0;36mBertForMaskedLM.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1341\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1342\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1343\u001b[0m \u001b[38;5;124;03m    Labels for computing the masked language modeling loss. Indices should be in `[-100, 0, ...,\u001b[39;00m\n\u001b[1;32m   1344\u001b[0m \u001b[38;5;124;03m    config.vocab_size]` (see `input_ids` docstring) Tokens with indices set to `-100` are ignored (masked), the\u001b[39;00m\n\u001b[1;32m   1345\u001b[0m \u001b[38;5;124;03m    loss is only computed for the tokens with labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1348\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1350\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1351\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1352\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1356\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1359\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1360\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1361\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1362\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1364\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1365\u001b[0m prediction_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcls(sequence_output)\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:983\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    981\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    982\u001b[0m     buffered_token_type_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings\u001b[38;5;241m.\u001b[39mtoken_type_ids[:, :seq_length]\n\u001b[0;32m--> 983\u001b[0m     buffered_token_type_ids_expanded \u001b[38;5;241m=\u001b[39m \u001b[43mbuffered_token_type_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    984\u001b[0m     token_type_ids \u001b[38;5;241m=\u001b[39m buffered_token_type_ids_expanded\n\u001b[1;32m    985\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (1454) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 1454].  Tensor sizes: [1, 512]"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(indexed_tokens)\n",
    "    predictions = outputs[0]\n",
    "values, indices=torch.sort(predictions[0, mask_pos],  descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ded98dc-c11d-4165-a477-9b47d0f8784d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_max_length, tokenizer.num_special_tokens_to_add(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e7cde59b-c71a-4ec5-96be-928a8e661f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "506"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_max_seq_len(prompt) -> int:\n",
    "    \"\"\"Compute the maximum sequence length of an input sequence.\n",
    "\n",
    "    Large input sequences need to be truncated while keeping the\n",
    "    prompt template untruncated.\n",
    "\n",
    "    Returns:\n",
    "        The maximum sequence length in number of tokens.\n",
    "    \"\"\"\n",
    "\n",
    "    template_len=len(tokenizer(prompt,add_special_tokens=False).input_ids)\n",
    "\n",
    "    n_special_chars = tokenizer.num_special_tokens_to_add(False)\n",
    "\n",
    "    max_seq_len = tokenizer.model_max_length \\\n",
    "        - (template_len + n_special_chars)\n",
    "\n",
    "    assert max_seq_len > 0\n",
    "\n",
    "    return max_seq_len\n",
    "\n",
    "text=df.loc[1,\"TextBody\"]\n",
    "prompt=\"It has [MASK] sentiment\"\n",
    "max_seq_len=compute_max_seq_len(prompt)\n",
    "max_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "37a5622b-4fd6-4d4d-a2b4-f7100a3616dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(315, 4)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexed_tokens=tokenizer(text,max_length=max_seq_len,truncation=True,add_special_tokens=False).input_ids\n",
    "index_prompt=tokenizer(prompt,add_special_tokens=False).input_ids\n",
    "len(indexed_tokens), len(index_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6c49842a-1d6f-42b9-a13b-cb8ac1233362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315\n",
      "319\n"
     ]
    }
   ],
   "source": [
    "tokenized_text= tokenizer.convert_ids_to_tokens(indexed_tokens)\n",
    "print(len(tokenized_text))\n",
    "tokenized_prompt=tokenizer.convert_ids_to_tokens(index_prompt)\n",
    "tokenized_text=tokenized_text+tokenized_prompt\n",
    "print(len(tokenized_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c486c2e8-4ee6-4902-9beb-541732da9b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'who pays the fu ##ta and sui taxes ? do you o ##do we need to report and pay those ? i know you collect and pay the fi ##ca / medicare . patty lawson hm ##ana ##get 512 - 380 - 710 ##8 f 512 - 45 ##9 - 145 ##9 this communication and any files o ##att ##ach ##ments transmitted with it may contain information that is confidential , privileged and exempt from disc ##los ##u ##und ##ea ##pp ##lica ##ble law . it is intended solely f ##oth ##e use of the individual ot ##he entity to which it is addressed . if you an ##ot the intended recipient , you ah ##ere ##by notified that any use , dissemination , o ##co ##py ##ing of this communication is strictly prohibited . if you have received this communication in er ##rop ##lea ##se not ##ify the send ##ea ##t once so that we may take the appropriate action . we aw ##or ##king with out ##ax unit on the request . they will be reaching out to you soon . please let us know if the ##is anything else we can assist with in the meantime . thank you , jessica br ##un ##hoe ##bes ##er ##vic ##e specialist un ##um client service cent ##e - 800 - ask - un ##um 1 - 800 - 275 - 86 ##86 hello team i hope you awe ##ll please assist with the request below regarding employ ##eta ##xes . thank you in advance f ##oy ##ou ##ass ##istan ##ce thank you , jessica br ##un ##hoe ##bes ##er ##vic ##e specialist un ##um client service cent ##e - 800 - ask - un ##um 1 - 800 - 275 - 86 ##86 the policy ##hold ##eis responsible f ##oa ##ny applicable fu ##ta / su ##ta thanks , nancy hook ##ey tr ##g it has [MASK] sentiment'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bda1811d-a72c-46b8-9f9d-25070a694766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'who pays the futa and sui taxes? do you odo we need to report and pay those? i know you collect and pay the fica / medicare. patty lawson hmanaget 512 - 380 - 7108 f 512 - 459 - 1459 this communication and any files oattachments transmitted with it may contain information that is confidential, privileged and exempt from disclosuundeapplicable law. it is intended solely fothe use of the individual othe entity to which it is addressed. if you anot the intended recipient, you ahereby notified that any use, dissemination, ocopying of this communication is strictly prohibited. if you have received this communication in erroplease notify the sendeat once so that we may take the appropriate action. we aworking with outax unit on the request. they will be reaching out to you soon. please let us know if theis anything else we can assist with in the meantime. thank you, jessica brunhoebeservice specialist unum client service cente - 800 - ask - unum 1 - 800 - 275 - 8686 hello team i hope you awell please assist with the request below regarding employetaxes. thank you in advance foyouassistance thank you, jessica brunhoebeservice specialist unum client service cente - 800 - ask - unum 1 - 800 - 275 - 8686 the policyholdeis responsible foany applicable futa / suta thanks, nancy hookey trg'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(indexed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "684f8da1-b074-4554-92f5-364421b67f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1297"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_text= tokenizer.decode(indexed_tokens)\n",
    "# \" \".join(tokenized_text)\n",
    "tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2800d07-fe25-4a71-b778-8b65c4f79bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "484"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexed_tokens=tokenizer(\" \".join(tokenized_text), return_tensors=\"pt\").input_ids\n",
    "tokenized_text= tokenizer.convert_ids_to_tokens(indexed_tokens[0])\n",
    "# take the first masked token\n",
    "mask_pos=tokenized_text.index(tokenizer.mask_token)\n",
    "\n",
    "mask_pos       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e54bc4a4-e6ea-43c4-b446-6e1bd8a49e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "319"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take the first masked token\n",
    "mask_pos=tokenized_text.index(tokenizer.mask_token)\n",
    "mask_pos       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ec6f6493-83db-41e1-a36e-ede670734719",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'torch.dtype' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [93], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 3\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(torch\u001b[38;5;241m.\u001b[39mlong(indexed_tokens\u001b[38;5;241m+\u001b[39mindex_prompt))\n\u001b[1;32m      4\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      5\u001b[0m values, indices\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39msort(predictions[\u001b[38;5;241m0\u001b[39m, mask_pos],  descending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'torch.dtype' object is not callable"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(torch.long(indexed_tokens+index_prompt))\n",
    "    predictions = outputs[0]\n",
    "values, indices=torch.sort(predictions[0, mask_pos],  descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b1ce8a9c-9e70-4a9f-8eeb-05dd4757f02d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer(prompt,add_special_tokens=False).input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb99daed-1e40-4ee0-95bc-944606d12023",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "d2087319-78c1-4176-ab31-0cfd7767950f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3893, 8699], [4997]]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_words=[[\"positive\",\"neutral\"],[\"negative\"]]\n",
    "def init_label_words(label_words: Optional[List[List[str]]]):\n",
    "    \"\"\"Initialize label words.\n",
    "\n",
    "    The entire vocabulary of the tokenizer is used as\n",
    "    label words if no label words are specified.\n",
    "\n",
    "    Args:\n",
    "        label_words: List of label words to use.\n",
    "    \"\"\"\n",
    "\n",
    "    if label_words is None:\n",
    "        # Use full vocabulary.\n",
    "        label_word_ids = [x for x in range(tokenizer.vocab_size)]\n",
    "        n_classes = tokenizer.vocab_size\n",
    "    else:\n",
    "        n_classes = len(label_words)\n",
    "        label_word_ids=[[] for _ in range(n_classes)]\n",
    "        for i, label in enumerate(label_words):\n",
    "            for char in label:\n",
    "                tokenized_label = tokenizer(char, add_special_tokens=False)['input_ids']\n",
    "                label_word_ids[i].append(tokenized_label[0])\n",
    "    return label_word_ids\n",
    "\n",
    "init_label_words(label_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "2ca29fed-9153-45fc-888b-65205dd9cb99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3893, 8699], [4997]]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_words=[[\"positive\",\"neutral\"],[\"negative\"]]\n",
    "n_classes = len(label_words)\n",
    "label_word_ids=[[] for _ in range(n_classes)]\n",
    "for i, label in enumerate(label_words):\n",
    "    for char in label:\n",
    "        tokenized_label = tokenizer(char, add_special_tokens=False)['input_ids']\n",
    "        label_word_ids[i].append(tokenized_label[0] )\n",
    "label_word_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "8259385f-5506-4570-8045-d86094c9bde1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 30522)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(tokenizer.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "2e4d8dab-893c-4620-9298-dbf460f7a33e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 100], [2]]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label_word_ids[0]\n",
    "label_word_ids=[[] for _ in range(2)]\n",
    "label_word_ids[0].append(1)\n",
    "label_word_ids[0].append(100)\n",
    "label_word_ids[1].append(2)\n",
    "label_word_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "a6e04c5b-f8c3-458b-9621-02fcfc14cc96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_word_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39efbe55-accf-44a3-8de0-e627ad92d2e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b78b256c-8609-42e3-baa8-c45e1121d4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return \"cuda:0\"  # Use only one GPU.\n",
    "    return \"cpu\"\n",
    "\n",
    "\n",
    "input_texts = [\n",
    "    \"This was terrible service\",\n",
    "    \"I want to terminate the policy.\"\n",
    "]\n",
    "# label_words = [[\"positive\",\"neutral\"], [\"negative\"]]\n",
    "label_words = [\"positive\", \"negative\"]\n",
    "\n",
    "cloze_template = ClozeTemplate([\"email:\", \"this email has {} sentiment\"])\n",
    "template=cloze_template.template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0bb8d223-8fe5-4e0e-aef1-5287f48ee92d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "503"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myclass=ClozeWrapper(tokenizer,template,label_words)\n",
    "max_seq_len=myclass.compute_max_seq_len()\n",
    "max_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e96b8782-4a0b-4cec-b122-6e346e731956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('[CLS]', '[SEP]', 101, 102, [[10373, 1024], [2023, 10373, 2038, 103, 15792]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.cls_token, tokenizer.sep_token, tokenizer.cls_token_id, tokenizer.sep_token_id, template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d62cbdc9-d254-4f31-8bda-f96e2935106c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cloze_template = ClozeTemplate([\"email:\", \"this email has {} sentiment\"])\n",
    "template=cloze_template.template\n",
    "prompts = []\n",
    "tokenized_inputs = tokenizer.batch_encode_plus(\n",
    "            input_texts,\n",
    "            add_special_tokens=False,\n",
    "            return_attention_mask=False,\n",
    "            truncation=True)['input_ids']\n",
    "\n",
    "def init_template(template: List[str]):\n",
    "\n",
    "    self_template = []\n",
    "    for text_snippet in template:\n",
    "        masked_text_snippet = text_snippet.format(\n",
    "            tokenizer.mask_token)\n",
    "        tokenized_text_snippet = tokenizer.encode(\n",
    "            masked_text_snippet,\n",
    "            add_special_tokens=False)\n",
    "        self_template.append(tokenized_text_snippet)\n",
    "    return self_template\n",
    "      \n",
    "template=init_template(template)\n",
    "\n",
    "for inp in tokenized_inputs:\n",
    "    truncated_input = inp[:max_seq_len]\n",
    "    # prompt = itertools.chain([tokenizer.cls_token_id],template[0], truncated_input,template[1],[tokenizer.sep_token_id])\n",
    "    prompt = itertools.chain(template[0], truncated_input,template[1])\n",
    "    prompts.append(list(prompt))\n",
    "\n",
    "# tokenized_prompts = tokenizer.batch_encode_plus(prompts, is_split_into_words=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a36e063e-91bd-484e-8a4d-4709de74416a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10373, 1024, 2023, 2001, 6659, 2326, 2023, 10373, 2038, 103, 15792], [10373, 1024, 1045, 2215, 2000, 20320, 1996, 3343, 1012, 2023, 10373, 2038, 103, 15792]]\n"
     ]
    }
   ],
   "source": [
    "print(prompts,end=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ec4b3d46-ebcd-4153-afef-15abb0a4451f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 12]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_id=[x.index(tokenizer.mask_token_id) for x in prompts]\n",
    "mask_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9be9b8b7-db83-4215-b070-233625a02919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['email : this was terrible service this email has [MASK] sentiment',\n",
       " 'email : i want to terminate the policy. this email has [MASK] sentiment']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokenizer.decode(x) for x in prompts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bc751eb1-57b0-438b-a7d5-801a4ddbf0c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 10373, 1024, 2023, 2001, 6659, 2326, 2023, 10373, 2038, 103, 15792, 102], [101, 10373, 1024, 1045, 2215, 2000, 20320, 1996, 3343, 1012, 2023, 10373, 2038, 103, 15792, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_prompts = tokenizer([tokenizer.decode(x) for x in prompts],truncation=True)\n",
    "tokenized_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f85630d1-a358-4dad-a272-2c642c37ad9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 10373, 1024, 2023, 2001, 6659, 2326, 2023, 10373, 2038, 103, 15792, 102], [101, 10373, 1024, 1045, 2215, 2000, 20320, 1996, 3343, 1012, 2023, 10373, 2038, 103, 15792, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_prompts = tokenizer([tokenizer.decode(x) for x in prompts])\n",
    "tokenized_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c168645-fefa-4d76-8a37-1ed123da0dbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5bccb9-9bd3-4fc3-a7b6-b0af14f884c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9511e532-d543-490b-8b0c-c0a989a1558a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[10373, 1024, 2023, 2001, 6659, 2326, 2023, 10373, 2038, 103, 15792],\n",
       " [10373,\n",
       "  1024,\n",
       "  1045,\n",
       "  2215,\n",
       "  2000,\n",
       "  20320,\n",
       "  1996,\n",
       "  3343,\n",
       "  1012,\n",
       "  2023,\n",
       "  10373,\n",
       "  2038,\n",
       "  103,\n",
       "  15792]]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_seq_len=myclass.compute_max_seq_len()\n",
    "template=cloze_template.template\n",
    "\n",
    "self_template = []\n",
    "for text_snippet in template:\n",
    "    masked_text_snippet = text_snippet.format(tokenizer.mask_token)\n",
    "    tokenized_text_snippet = tokenizer.encode(masked_text_snippet,\n",
    "                                              add_special_tokens=False)\n",
    "    self_template.append(tokenized_text_snippet)\n",
    "\n",
    "            \n",
    "\n",
    "def gen_prompts(inputs: List[List[int]], *args,**kwargs) -> BatchEncoding:\n",
    "    \"\"\"Generate prompts.\n",
    "\n",
    "    Args:\n",
    "        inputs: Batch of inputs represented as lists of token ids.\n",
    "\n",
    "    Returns:\n",
    "        Prompts generated from inputs (as lists of token ids).\n",
    "    \"\"\"\n",
    "\n",
    "    prompts = []\n",
    "    for inp in inputs:\n",
    "        truncated_input = inp[:max_seq_len]\n",
    "\n",
    "        prompt = itertools.chain(self_template[0], truncated_input,self_template[1])\n",
    "\n",
    "        prompts.append(list(prompt))\n",
    "\n",
    "    # tokenized_prompts = tokenizer.batch_encode_plus(\n",
    "    #     prompts, is_split_into_words=True, *args, **kwargs)\n",
    "\n",
    "    return prompts\n",
    "    \n",
    "def preprocess_inputs(inputs: Union[List[str], List[int]], *args, **kwargs) -> BatchEncoding:\n",
    "    \"\"\"Preprocesses inputs by mapping them to their prompts.\n",
    "\n",
    "    Args:\n",
    "        inputs: List of input strings or lists of token ids.\n",
    "\n",
    "    Returns:\n",
    "        Prompts represented as lists of token ids.\n",
    "    \"\"\"\n",
    "\n",
    "    is_not_pretokenized = isinstance(inputs[0], str)\n",
    "\n",
    "    if is_not_pretokenized:\n",
    "        tokenized_inputs = tokenizer.batch_encode_plus(\n",
    "            inputs,\n",
    "            add_special_tokens=False,\n",
    "            return_attention_mask=False,\n",
    "            truncation=True)['input_ids']\n",
    "    else:\n",
    "        tokenized_inputs = inputs\n",
    "\n",
    "    prompts = gen_prompts(tokenized_inputs, *args, **kwargs)\n",
    "\n",
    "    return prompts\n",
    "\n",
    "preprocess_inputs(input_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "dfb0d263-03e2-482d-8f84-d3b8d0fe4a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=input_texts\n",
    "is_not_pretokenized = isinstance(inputs[0], str)\n",
    "tokenized_inputs = tokenizer.batch_encode_plus(\n",
    "    inputs,\n",
    "    add_special_tokens=False,\n",
    "    return_attention_mask=False,\n",
    "    truncation=True)['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8585fbb6-1729-4c87-b7d9-8282a05b5e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2023, 2001, 6659, 2326], [1045, 2215, 2000, 20320, 1996, 3343, 1012]]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d3cd50ba-f668-432f-9ab9-de62c61da6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = []\n",
    "inputs=tokenized_inputs\n",
    "for inp in inputs:\n",
    "    truncated_input = inp[:max_seq_len]\n",
    "\n",
    "    prompt = itertools.chain(self_template[0], truncated_input,self_template[1])\n",
    "\n",
    "    prompts.append(list(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a77a93e-8ae5-4692-81f6-6cfaa491ff32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "outputs=torch.randn(3,10,100)\n",
    "label_word_ids=[[2,8],[14]]\n",
    "masked_idx=8\n",
    "softmax_output=True\n",
    "logit=torch.zeros(outputs.shape[0],len(label_word_ids),dtype=torch.float)\n",
    "for i,label_ids in enumerate(label_word_ids):\n",
    "    x=0\n",
    "    for ids in label_ids:\n",
    "        x+=outputs[:, :, ids][:,masked_idx]\n",
    "    logit[:,i]=x\n",
    "if softmax_output:\n",
    "    logit=logit.softmax(dim=-1)\n",
    "logit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70005fdd-9530-4249-bb8e-0af242c770e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5923, 0.4077],\n",
       "        [0.6991, 0.3009],\n",
       "        [0.9214, 0.0786]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b3c77b5a-3019-4479-9ff9-317119751779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[10373, 1024], [2023, 10373, 2038, 103, 15792]]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    def parse_outputs(self,\n",
    "                      outputs: torch.Tensor,\n",
    "                      masked_idx: torch.Tensor,\n",
    "                      softmax_output=True) -> torch.Tensor:\n",
    "        \"\"\"Parse outputs of a MLM model.\n",
    "\n",
    "        The MLM model outputs a probability distribution over the entire\n",
    "        vocabulary for each element in an input sequence.\n",
    "        This method convert the outputs associated with an\n",
    "        input text to an output of the text classification problem.\n",
    "\n",
    "        Args:\n",
    "            outputs: A batch of outputs produced by the MLM model.\n",
    "            masked_idx: Indices of masked positions for each output.\n",
    "            softmax_output: True if softmax should be computed over the outputs.\n",
    "\n",
    "        Returns:\n",
    "            Tensor with output predictions over the classes of interest.\n",
    "        \"\"\"\n",
    "        logit=torch.zeros(outputs.shape[0],len(label_word_ids),dtype=torch.float)\n",
    "        for i,label_ids in enumerate(label_word_ids):\n",
    "            x=0\n",
    "            for ids in label_ids:\n",
    "                x+=outputs[:, :, ids][:,masked_idx]\n",
    "            logit[:,i]=x\n",
    "        if softmax_output:\n",
    "            logit=logit.softmax(dim=-1)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2410eec-c2a9-4067-8684-b06b2794e5ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe3bb64f-3538-44cb-8ce1-dc6860ff2546",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import abstractmethod\n",
    "from typing import Optional, Union,List,Dict\n",
    "import itertools\n",
    "\n",
    "import torch\n",
    "from transformers import PreTrainedTokenizer, PreTrainedModel\n",
    "from transformers.tokenization_utils_base import BatchEncoding\n",
    "\n",
    "\"\"\"\n",
    "Classes for zero/few-shot text classification, with HuggingFace models.\n",
    "\n",
    "Two methods are implemented:\n",
    "- 'Cloze' based on Shick et. al. (2020)\n",
    "\n",
    "Example usage:\n",
    "\n",
    "    input_texts = [\n",
    "        \"This was terrible service\",\n",
    "        \"I want to terminate the policy.\"\n",
    "    ]\n",
    "    label_words = [[\"positive\",\"neutral\"], [\"negative\"]]\n",
    "\n",
    "    cloze_template = ClozeTemplate([\"email:\", \"this email has {} sentiment\"])\n",
    "    cloze_wrapper = ClozeWrapper(\n",
    "        mlm_model_tokenizer,\n",
    "        cloze_template,\n",
    "        label_words\n",
    "    )\n",
    "    cloze_preds = cloze_wrapper(mlm_model, input_texts)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "class ClozeTemplate():\n",
    "    \"\"\"Prompt template for the cloze method.\n",
    "\n",
    "    A prompt template is given on the form [prepended_str, appended_str],\n",
    "    where either prepended_str or appended_str contains a single\n",
    "    empty placeholder {} representing the masked position.\n",
    "    The resulting prompt of an input x is:\n",
    "    prompt(x) = prepended_str + x + appended_str\n",
    "\n",
    "    Example:\n",
    "        The prompt template [\"\", \"This text is about {}.\"]\n",
    "        produces the prompt \"[input text] This text is about [MASK].\"\n",
    "    \"\"\"\n",
    "    def __init__(self, template: List[str]):\n",
    "        assert len(template) == 2\n",
    "\n",
    "        masked_position_token = \"{}\"\n",
    "        n_masked_position_token = sum([\n",
    "            text_snippet.count(masked_position_token)\n",
    "            for text_snippet in template\n",
    "        ])\n",
    "        assert n_masked_position_token == 1\n",
    "\n",
    "        self.template = template\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        template = [s.format(\"_\") for s in self.template]\n",
    "        return ''.join(['[', template[0], '][', template[1], ']'])\n",
    "    \n",
    "\n",
    "class Wrapper:\n",
    "    \"\"\"Zero/few-shot classification wrapper for usage with HuggingFace.\n",
    "\n",
    "    Uses a prompt template and a list of label words to produce\n",
    "    input to the underlying language model, and to parse its outputs.\n",
    "\n",
    "    The label words define a one-to-one mapping between the tokens of the\n",
    "    language model and the classes of the classification problem.\n",
    "    The prompt template is used to reformulate the classification problem\n",
    "    as an instance of the NLP problem the language model has been trained on.\n",
    "    \"\"\"\n",
    "    def __init__(self, tokenizer: PreTrainedTokenizer, template, label_words):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.init_label_words(label_words)\n",
    "        self.init_template(template)\n",
    "        self.device = self.get_device()\n",
    "        \n",
    "    def get_device(self):\n",
    "        if torch.cuda.is_available():\n",
    "            return \"cuda:0\"  # Use only one GPU.\n",
    "        return \"cpu\"\n",
    "\n",
    "    @classmethod\n",
    "    @abstractmethod\n",
    "    def init_template(cls, template):\n",
    "        \"\"\"Initialize prompt template.\"\"\"\n",
    "\n",
    "    @classmethod\n",
    "    @abstractmethod\n",
    "    def init_label_words(cls, label_words):\n",
    "        \"\"\"Initialize label words.\"\"\"\n",
    "\n",
    "    @classmethod\n",
    "    @abstractmethod\n",
    "    def preprocess_inputs(cls, self, inputs, *args, **kwargs):\n",
    "        \"\"\"Preprocess a batch of text inputs.\n",
    "\n",
    "        Useful for data loader pipelines.\n",
    "        \"\"\"\n",
    "\n",
    "    @classmethod\n",
    "    @abstractmethod\n",
    "    def forward(cls, model, inputs, softmax_output):\n",
    "        \"\"\"Forward pass using inputs produced by preprocess_inputs.\"\"\"\n",
    "\n",
    "    @classmethod\n",
    "    @abstractmethod\n",
    "    def __call__(cls, model, inputs):\n",
    "        \"\"\"Compute output probabilities of a batch of input texts.\"\"\"\n",
    "\n",
    "    def to_device(self, inputs):\n",
    "        \"\"\"Put inputs on device. \"\"\"\n",
    "        return {\n",
    "            name: tensor.to(self.device)\n",
    "            for name, tensor in inputs.items()\n",
    "        }\n",
    "\n",
    "\n",
    "class ClozeWrapper(Wrapper):\n",
    "    \"\"\"Wrapper for the Cloze Method (Schick et al. 2021).\n",
    "\n",
    "    Text classification is reframed as a MLM problem.\n",
    "    An input text is mapped to a prompt by a prompt template,\n",
    "    which adds text containing a single [MASK] token to it.\n",
    "\n",
    "    Reference:\n",
    "    https://aclanthology.org/2021.eacl-main.20.pdf\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 tokenizer: PreTrainedTokenizer,\n",
    "                 template: ClozeTemplate,\n",
    "                 label_words: Optional[List[str]] = None):\n",
    "        super().__init__(tokenizer, template, label_words)\n",
    "        self.max_seq_len = self.compute_max_seq_len()\n",
    "\n",
    "    def init_template(self, template: List[str]):\n",
    "        \"\"\"Initialize the prompt template.\n",
    "\n",
    "        The prompt template is saved in its tokenized format.\n",
    "\n",
    "        Args:\n",
    "            template: The prompt template to use.\n",
    "        \"\"\"\n",
    "\n",
    "        self.template = []\n",
    "        for text_snippet in template:\n",
    "            masked_text_snippet = text_snippet.format(\n",
    "                self.tokenizer.mask_token)\n",
    "            tokenized_text_snippet = self.tokenizer.encode(\n",
    "                masked_text_snippet,\n",
    "                add_special_tokens=False)\n",
    "            self.template.append(tokenized_text_snippet)\n",
    "\n",
    "    def compute_max_seq_len(self) -> int:\n",
    "        \"\"\"Compute the maximum sequence length of an input sequence.\n",
    "\n",
    "        Large input sequences need to be truncated while keeping the\n",
    "        prompt template untruncated.\n",
    "\n",
    "        Returns:\n",
    "            The maximum sequence length in number of tokens.\n",
    "        \"\"\"\n",
    "        template_len = len(self.template[0]) + len(self.template[1])\n",
    "        n_special_chars = self.tokenizer.num_special_tokens_to_add(False)\n",
    "\n",
    "        max_seq_len = self.tokenizer.model_max_length \\\n",
    "            - (template_len + n_special_chars)\n",
    "\n",
    "        assert max_seq_len > 0\n",
    "\n",
    "        return max_seq_len\n",
    "\n",
    "    def init_label_words(self, label_words: Optional[List[str]]):\n",
    "        \"\"\"Initialize label words.\n",
    "\n",
    "        The entire vocabulary of the tokenizer is used as\n",
    "        label words if no label words are specified.\n",
    "\n",
    "        Args:\n",
    "            label_words: List of label words to use.\n",
    "        \"\"\"\n",
    "\n",
    "        if label_words is None:\n",
    "            # Use full vocabulary.\n",
    "            self.label_word_ids = [x for x in range(self.tokenizer.vocab_size)]\n",
    "            self.n_classes = self.tokenizer.vocab_size\n",
    "        else:\n",
    "            self.n_classes = len(label_words)\n",
    "            self.label_word_ids=[[] for _ in range(self.n_classes)]\n",
    "            for i, label in enumerate(label_words):\n",
    "                for char in label:\n",
    "                    tokenized_label = self.tokenizer(char, add_special_tokens=False)['input_ids']\n",
    "                    self.label_word_ids[i].append(tokenized_label[0])                \n",
    "\n",
    "    def gen_prompts(self, inputs: List[List[int]], *args,\n",
    "                    **kwargs) -> BatchEncoding:\n",
    "        \"\"\"Generate prompts.\n",
    "\n",
    "        Args:\n",
    "            inputs: Batch of inputs represented as lists of token ids.\n",
    "\n",
    "        Returns:\n",
    "            Prompts generated from inputs (as lists of token ids).\n",
    "        \"\"\"\n",
    "\n",
    "        prompts = []\n",
    "        for inp in inputs:\n",
    "            truncated_input = inp[:self.max_seq_len]\n",
    "\n",
    "            prompt = itertools.chain(self.template[0], truncated_input,self.template[1])\n",
    "            \n",
    "            prompts.append(list(prompt))\n",
    "\n",
    "        # tokenized_prompts = self.tokenizer.batch_encode_plus(\n",
    "        #     prompts, is_split_into_words=True, *args, **kwargs)\n",
    "        # return tokenized_prompts\n",
    "        return prompts\n",
    "\n",
    "    def preprocess_inputs(self, inputs: Union[List[str], List[int]], *args,\n",
    "                          **kwargs) -> BatchEncoding:\n",
    "        \"\"\"Preprocesses inputs by mapping them to their prompts.\n",
    "\n",
    "        Args:\n",
    "            inputs: List of input strings or lists of token ids.\n",
    "\n",
    "        Returns:\n",
    "            Prompts represented as lists of token ids.\n",
    "        \"\"\"\n",
    "\n",
    "        is_not_pretokenized = isinstance(inputs[0], str)\n",
    "\n",
    "        if is_not_pretokenized:\n",
    "            tokenized_inputs = self.tokenizer.batch_encode_plus(\n",
    "                inputs,\n",
    "                add_special_tokens=False,\n",
    "                return_attention_mask=False,\n",
    "                truncation=True)['input_ids']\n",
    "        else:\n",
    "            tokenized_inputs = inputs\n",
    "\n",
    "        prompts = self.gen_prompts(tokenized_inputs, *args, **kwargs)\n",
    "\n",
    "        return prompts\n",
    "\n",
    "    def parse_outputs(self,\n",
    "                      outputs: torch.Tensor,\n",
    "                      masked_idx: torch.Tensor,\n",
    "                      softmax_output=True) -> torch.Tensor:\n",
    "        \"\"\"Parse outputs of a MLM model.\n",
    "\n",
    "        The MLM model outputs a probability distribution over the entire\n",
    "        vocabulary for each element in an input sequence.\n",
    "        This method convert the outputs associated with an\n",
    "        input text to an output of the text classification problem.\n",
    "\n",
    "        Args:\n",
    "            outputs: A batch of outputs produced by the MLM model.\n",
    "            masked_idx: Indices of masked positions for each output.\n",
    "            softmax_output: True if softmax should be computed over the outputs.\n",
    "\n",
    "        Returns:\n",
    "            Tensor with output predictions over the classes of interest.\n",
    "        \"\"\"\n",
    "\n",
    "        logit=torch.zeros(outputs.shape[0],len(label_word_ids),dtype=torch.float)\n",
    "        for i,label_ids in enumerate(label_word_ids):\n",
    "            x=0\n",
    "            for ids in label_ids:\n",
    "                x+=outputs[:, :, ids][:,masked_idx]\n",
    "            logit[:,i]=x\n",
    "        if softmax_output:\n",
    "            logit=logit.softmax(dim=-1)\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def get_masked_idx(self, inputs: Dict[str, torch.Tensor]) -> torch.Tensor:\n",
    "        \"\"\"Get position of masked indices in inputs.\"\"\"\n",
    "        return torch.where(\n",
    "            inputs['input_ids'] == self.tokenizer.mask_token_id)[1]\n",
    "\n",
    "    def forward(self,\n",
    "                model: PreTrainedModel,\n",
    "                inputs: BatchEncoding,\n",
    "                softmax_output=True) -> torch.Tensor:\n",
    "\n",
    "        prompts = self.to_device(inputs)\n",
    "        masked_idx = self.get_masked_idx(prompts)\n",
    "        outputs = model(**prompts).logits\n",
    "        parsed_outputs = self.parse_outputs(outputs, masked_idx,\n",
    "                                            softmax_output)\n",
    "\n",
    "        return parsed_outputs\n",
    "\n",
    "    def __call__(self, model, inputs, softmax_output=True):\n",
    "        with torch.no_grad():\n",
    "            inputs = self.preprocess_inputs(inputs,\n",
    "                                            return_tensors=\"pt\",\n",
    "                                            padding=True)\n",
    "            outputs = self.forward(model, inputs, softmax_output)\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd70e68-1695-4105-ba1a-0e224133f463",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3839e3-5215-43bc-b9c8-4ad7a05735f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0275aa06-1c48-4d2e-ac5d-062beb407868",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134376c5-c7c3-4c3e-8ccc-fad8f98b6cb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7106d6a-3db8-40cf-8db4-cfe807a66ff0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638a51db-0089-4383-9e0e-49fe6f8a48e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048921cc-2a5a-4056-b195-078f3bffbd1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c79ff1-f11e-4198-b5e1-32b38d6f24ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Classes for zero/few-shot text classification, with HuggingFace models.\n",
    "\n",
    "Two methods are implemented:\n",
    "- 'Cloze' based on Shick et. al. (2020)\n",
    "- 'Entailment' based on Yin et al. (2019)\n",
    "\n",
    "Example usage:\n",
    "\n",
    "    input_texts = [\n",
    "        \"This was the greatest movie I've ever seen!\",\n",
    "        \"I hated this movie.\"\n",
    "    ]\n",
    "    label_words = [\"positive\", \"negative\"]\n",
    "\n",
    "    cloze_template = ClozeTemplate([\"Movie review:\", \"This review is {}.\"])\n",
    "    cloze_wrapper = ClozeWrapper(\n",
    "        mlm_model_tokenizer,\n",
    "        cloze_template,\n",
    "        label_words\n",
    "    )\n",
    "    cloze_preds = cloze_wrapper(mlm_model, input_texts)\n",
    "\n",
    "    entailment_template = EntailmentTemplate(\"This review is {}.\")\n",
    "    entailment_wrapper = EntailmentWrapper(\n",
    "        nli_model_tokenizer,\n",
    "        entailment_template,\n",
    "        label_words\n",
    "    )\n",
    "    entailment_preds = entailment_wrapper(nli_model, input_texts)\n",
    "\"\"\"\n",
    "\n",
    "from abc import abstractmethod\n",
    "from typing import Optional, Union\n",
    "import itertools\n",
    "\n",
    "import torch\n",
    "from transformers import PreTrainedTokenizer, PreTrainedModel\n",
    "from transformers.tokenization_utils_base import BatchEncoding\n",
    "\n",
    "from .utils import get_device\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class EntailmentTemplate():\n",
    "    \"\"\"Prompt template for the entailment method.\n",
    "\n",
    "    A prompt template is given as a string containing a single empty\n",
    "    placeholder {}, which is to be replaced by label words.\n",
    "    \"\"\"\n",
    "    def __init__(self, template: str):\n",
    "        label_word_token = \"{}\"\n",
    "        assert template.count(label_word_token) == 1\n",
    "\n",
    "        self.template = template\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return self.template.format(\"_\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class EntailmentWrapper(Wrapper):\n",
    "    \"\"\"Wrapper for the entailment method (Yin et al. 2019).\n",
    "\n",
    "    Text classification is reframed as a textual entailment problem,\n",
    "    where the input text is given as the premise.\n",
    "    A hypothesis is formulated for each label word, using a prompt template.\n",
    "    Each hypothesis produces an output probability representing\n",
    "    its likelihood, and the final probability distribution is obtained\n",
    "    by taking the softmax over each of these probabilities.\n",
    "\n",
    "    Reference:\n",
    "    https://aclanthology.org/D19-1404.pdf\n",
    "    \"\"\"\n",
    "    def __init__(self, tokenizer: PreTrainedTokenizer,\n",
    "                 template: EntailmentTemplate, label_words):\n",
    "        super().__init__(tokenizer, template.template, label_words)\n",
    "\n",
    "    def init_label_words(self, label_words: list[str]):\n",
    "        self.label_words = label_words\n",
    "        self.n_classes = len(label_words)\n",
    "\n",
    "    def init_template(self, template: str):\n",
    "        \"\"\"Initialize prompt template.\n",
    "\n",
    "        Generates all hypotheses using the label words,\n",
    "        and tokenizes them.\n",
    "\n",
    "        Args:\n",
    "            template: Prompt template to use.\n",
    "        \"\"\"\n",
    "\n",
    "        self.hypotheses = self.tokenizer(\n",
    "            [template.format(label_word) for label_word in self.label_words],\n",
    "            add_special_tokens=False,\n",
    "            return_attention_mask=False)['input_ids']\n",
    "\n",
    "    def preprocess_inputs(self, inputs: list[str], *args,\n",
    "                          **kwargs) -> BatchEncoding:\n",
    "        \"\"\"Tokenize inputs.\n",
    "\n",
    "        Args:\n",
    "            inputs: A batch of input texts.\n",
    "\n",
    "        Returns:\n",
    "            Tokenized inputs.\n",
    "        \"\"\"\n",
    "\n",
    "        tokenized_inputs = self.tokenizer(inputs,\n",
    "                                          add_special_tokens=False,\n",
    "                                          return_attention_mask=False,\n",
    "                                          return_length=True\n",
    "                                          *args,\n",
    "                                          **kwargs)\n",
    "\n",
    "        return tokenized_inputs\n",
    "\n",
    "    def parse_outputs(self,\n",
    "                      outputs: torch.Tensor,\n",
    "                      softmax_output=True) -> torch.Tensor:\n",
    "        \"\"\"Parse outputs of an NLI model.\n",
    "\n",
    "        The NLI model outputs a probability distribution over\n",
    "        three classes (non-entailment, neutral, entailment)\n",
    "        for each (input_text, hypothesis) pair.\n",
    "        This method convert the outputs associated with an\n",
    "        input text to an output of the text classification problem.\n",
    "\n",
    "        Args:\n",
    "            outputs: A batch of outputs produced by the NLI model.\n",
    "            softmax_output (optional): [description]. Defaults to True.\n",
    "\n",
    "        Returns:\n",
    "            Tensor with output predictions over the classes of interest.\n",
    "        \"\"\"\n",
    "\n",
    "        # Ignore the neutral label.\n",
    "        entailment_probs = outputs[:, [0, 2]]\n",
    "\n",
    "        entailment_probs = entailment_probs.softmax(dim=1)\n",
    "        entailment_probs = entailment_probs[:, 1]\n",
    "        class_probs = torch.reshape(entailment_probs, (-1, self.n_classes))\n",
    "\n",
    "        if softmax_output:\n",
    "            class_probs = class_probs.softmax(dim=-1)\n",
    "\n",
    "        return class_probs\n",
    "\n",
    "    def gen_prompts(self, inputs: BatchEncoding) -> torch.Tensor:\n",
    "        \"\"\"Generate prompts.\n",
    "\n",
    "        Args:\n",
    "            inputs: Batch with tokenized input texts.\n",
    "\n",
    "        Returns:\n",
    "            Tensor with tokenized prompts.\n",
    "        \"\"\"\n",
    "\n",
    "        if 'attention_mask' in inputs:\n",
    "            # There should not be any padding between an input text (premise)\n",
    "            # and a hypothesis.\n",
    "            non_padded_inputs = [\n",
    "                inp[attn == 1].tolist() for inp, attn in zip(\n",
    "                    inputs['input_ids'], inputs['attention_mask'])\n",
    "            ]\n",
    "        else:\n",
    "            non_padded_inputs = inputs['input_ids']\n",
    "\n",
    "        prompts = []\n",
    "        for inp in non_padded_inputs:\n",
    "            for hypothesis in self.hypotheses:\n",
    "                prompts.append([inp, hypothesis])\n",
    "\n",
    "        tokenized_prompts = self.tokenizer.batch_encode_plus(\n",
    "            prompts,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=\"only_first\",\n",
    "            is_split_into_word=True)\n",
    "\n",
    "        return tokenized_prompts\n",
    "\n",
    "    def forward(self,\n",
    "                model: PreTrainedModel,\n",
    "                inputs: BatchEncoding,\n",
    "                softmax_output: bool = True) -> torch.Tensor:\n",
    "\n",
    "        prompts = self.gen_prompts(inputs)\n",
    "        tokenized_prompts = self.to_device(prompts)\n",
    "        outputs = model(**tokenized_prompts).logits\n",
    "        parsed_outputs = self.parse_outputs(outputs, softmax_output)\n",
    "\n",
    "        return parsed_outputs\n",
    "\n",
    "    def __call__(self, model, inputs, softmax_output=True):\n",
    "        with torch.no_grad():\n",
    "            inputs = self.preprocess_inputs(inputs, return_tensors=\"np\")\n",
    "            outputs = self.forward(model, inputs, softmax_output)\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297f11c2-73af-4026-9838-f399fdab6e8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531ab26d-d47c-4bff-bc3c-3b32d2852164",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9008be8e-75aa-4292-a992-e02e18fe60c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizer, PreTrainedModel\n",
    "from transformers.tokenization_utils_base import BatchEncoding\n",
    "from transformers import AutoModelForMaskedLM , AutoTokenizer\n",
    "from typing import Optional, Union,List,Dict\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3aef90a-cc7a-407d-ae4c-f05424bf4b49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919ad236-dd64-40be-82bb-3d6d128d0cd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d6055c6-bf0c-4887-99e9-947680b88cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[email:][This email has _ sentiment]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ClozeTemplate():\n",
    "    \"\"\"Prompt template for the cloze method.\n",
    "\n",
    "    A prompt template is given on the form [prepended_str, appended_str],\n",
    "    where either prepended_str or appended_str contains a single\n",
    "    empty placeholder {} representing the masked position.\n",
    "    The resulting prompt of an input x is:\n",
    "    prompt(x) = prepended_str + x + appended_str\n",
    "\n",
    "    Example:\n",
    "        The prompt template [\"\", \"This text is about {}.\"]\n",
    "        produces the prompt \"[input text] This text is about [MASK].\"\n",
    "    \"\"\"\n",
    "    def __init__(self, template: List[str]):\n",
    "        assert len(template) == 2\n",
    "\n",
    "        masked_position_token = \"{}\"\n",
    "        n_masked_position_token = sum([\n",
    "            text_snippet.count(masked_position_token)\n",
    "            for text_snippet in template\n",
    "        ])\n",
    "        assert n_masked_position_token == 1\n",
    "\n",
    "        self.template = template\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        template = [s.format(\"_\") for s in self.template]\n",
    "        return ''.join(['[', template[0], '][', template[1], ']'])\n",
    "    \n",
    "template=[\"email:\", \"This email has {} sentiment\"]\n",
    "myclass=ClozeTemplate(template)\n",
    "myclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7a8c94e-cbe1-4cf3-9f89-a8c3e3b6dc6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 28.0/28.0 [00:00<00:00, 18.9kB/s]\n",
      "Downloading: 100%|██████████| 571/571 [00:00<00:00, 469kB/s]\n",
      "Downloading: 100%|██████████| 226k/226k [00:00<00:00, 41.7MB/s]\n",
      "Downloading: 100%|██████████| 455k/455k [00:00<00:00, 54.8MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[10373, 1024], [2023, 10373, 2038, 103, 15792]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path=\"bert-large-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "x = []\n",
    "for text_snippet in template:\n",
    "    masked_text_snippet = text_snippet.format(tokenizer.mask_token)\n",
    "    tokenized_text_snippet = tokenizer.encode(masked_text_snippet, add_special_tokens=False)\n",
    "    x.append(tokenized_text_snippet)\n",
    "    \n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61f1fd21-f921-4caf-8ac4-cd33b56481b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2023, 10373, 2038, 103, 15792]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(masked_text_snippet, add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0245cda6-e55c-4885-9415-36c675c35cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0388, -0.1688,  0.1220,  0.0607,  0.5187],\n",
       "         [-0.2241, -0.9021,  0.4021,  0.1500,  0.4735],\n",
       "         [ 2.7840,  0.5231, -0.1815,  2.6400, -1.2372],\n",
       "         [ 0.6888,  0.1721,  2.2258,  0.1697, -0.1007],\n",
       "         [-0.2209,  0.6775, -1.1835, -0.3678, -0.1849],\n",
       "         [-0.8734, -1.1900,  0.6574,  1.1225, -2.2173],\n",
       "         [-0.8795, -0.0941, -1.3170,  0.1017,  1.3301],\n",
       "         [ 0.4299,  0.9585,  1.6229,  0.0451,  0.3493],\n",
       "         [ 1.6662,  1.8358,  1.1899,  0.9666, -0.1843],\n",
       "         [ 0.2287,  1.0212,  0.3104,  0.0036,  0.5682]],\n",
       "\n",
       "        [[-0.5780, -0.3849, -0.3517,  1.0626,  0.3280],\n",
       "         [-0.8508,  0.1457, -0.0664, -0.2225,  1.3377],\n",
       "         [-0.1595,  0.2485,  0.0106,  0.0487, -0.4561],\n",
       "         [-0.2040, -1.3237, -0.1600,  1.7919,  1.0017],\n",
       "         [ 0.7338,  1.3518, -1.0816,  0.6020,  1.0964],\n",
       "         [-1.9872, -0.2697, -0.5012,  1.3736,  0.4318],\n",
       "         [-1.3920,  1.3023,  0.3191, -0.8291, -0.7722],\n",
       "         [-0.2470,  0.4126,  0.2044, -1.1355,  0.7256],\n",
       "         [-0.1286,  0.3282, -0.7515,  1.0281,  0.5106],\n",
       "         [-2.0637, -0.0314, -0.6857, -1.0166,  0.1867]],\n",
       "\n",
       "        [[-0.2729,  0.1983, -1.6810,  0.3606, -0.8102],\n",
       "         [-0.4868,  1.7987, -1.4388,  0.7151, -0.0207],\n",
       "         [ 0.1464, -0.9029,  1.1601, -0.4530,  0.3630],\n",
       "         [-0.0490,  0.0211, -1.3606, -2.5847, -1.1776],\n",
       "         [ 0.8725,  1.0080, -0.0445, -0.2950, -0.2293],\n",
       "         [-0.2957, -1.4903,  0.7527, -1.2804, -0.3445],\n",
       "         [ 1.3500, -0.3144,  0.0563,  0.2562, -0.6586],\n",
       "         [-0.8160, -2.3498, -0.0858, -1.4768,  0.5981],\n",
       "         [-0.0854,  0.6024,  1.6409, -1.5739,  0.3539],\n",
       "         [ 0.0041, -1.5809,  0.5742, -0.3150, -0.5478]]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.randn(3,10,5)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "653ebb60-42e6-4e7d-9d4d-23da8f68ebab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.sort(\n",
       "values=tensor([[ 1.8358,  1.6662,  1.1899,  0.9666, -0.1843],\n",
       "        [ 1.0281,  0.5106,  0.3282, -0.1286, -0.7515],\n",
       "        [ 1.6409,  0.6024,  0.3539, -0.0854, -1.5739]]),\n",
       "indices=tensor([[1, 0, 2, 3, 4],\n",
       "        [3, 4, 1, 0, 2],\n",
       "        [2, 1, 4, 0, 3]]))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sort(x[:,8],descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8541dc87-3f90-4096-a53c-2060d8c4177f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values,index=torch.sort(x[:,8],descending=True,dim=-1)\n",
    "index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "76e7f566-d8a9-4179-ac2a-06aa95851b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.8358,  1.6662,  1.1899,  0.9666, -0.1843],\n",
       "        [ 1.0281,  0.5106,  0.3282, -0.1286, -0.7515],\n",
       "        [ 1.6409,  0.6024,  0.3539, -0.0854, -1.5739]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fde8885-5240-456a-a1ea-1c0e38f1bb36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
