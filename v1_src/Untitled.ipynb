{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c093379c-6430-4780-8669-994faf6de512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version is 1.9.1+cu111\n",
      "Transformers version is 4.6.1\n",
      "\n",
      "Namespace(adam_epsilon=1e-08, batch_size=20, data='Full_TextBody_truncation_tail_bert', feature_name='Full_TextBody', fp16=False, frozen_layers=6, gpus=[0, 1], gradient_accumulation_steps=8, loss_weight=False, lr=2e-05, lr_scheduler_type='linear', model_checkpoint='roberta-base', model_output_name='bert_Full_TextBody_tail', num_epochs=10, output_dir='/home/ec2-user/SageMaker/retention_model_NLP/v1_src/bert_repo_Full_TextBody_tail', seed=101, shuffle_train=True, test_negative_positive_ratio=10, train_negative_positive_ratio=4, truncation_strategy='tail', undersampling=False, use_schedule=False, validation_split=0.2, warmup_ratio=0.4, weight_decay=0.0001)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1017dd057aab4ce59f1d346f73cae9aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8e37ce5e4fe4ccfb06d25805b4f2a3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The # of availabe GPU(s):     2         \n",
      "GPU Name:                     NVIDIA A10G\n",
      "GPU Name:                     NVIDIA A10G\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from collections import defaultdict\n",
    "import argparse\n",
    "import logging\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, f1_score,average_precision_score\n",
    "from sklearn.metrics import precision_recall_fscore_support \n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc as auc_score\n",
    "\n",
    "import torch\n",
    "print(\"torch version is {}\".format(torch.__version__))\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from datasets import load_dataset, load_metric, concatenate_datasets,DatasetDict,Dataset\n",
    "from datasets import load_from_disk\n",
    "\n",
    "import transformers\n",
    "print(\"Transformers version is {}\".format(transformers.__version__))\n",
    "\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    AutoConfig,\n",
    "    AutoModel,\n",
    "    AutoModelWithLMHead,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    default_data_collator,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    get_scheduler\n",
    ")\n",
    "\n",
    "from accelerate import Accelerator\n",
    "\n",
    "import utils\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "    \n",
    "def main(args,train_data, test_data):\n",
    "    train_data.set_format(type=\"pandas\")\n",
    "    df_train=train_data[:]\n",
    "    test_data.set_format(type=\"pandas\")\n",
    "    df_test=test_data[:]\n",
    "    \n",
    "    ## undersample netative sample so that the negative/positive=4\n",
    "    df_train=utils.under_sampling(df_train,'churn', args.seed, args.train_negative_positive_ratio)\n",
    "    df_test=utils.under_sampling(df_test,'churn', args.seed, args.test_negative_positive_ratio)\n",
    "    df_train.reset_index(drop=True, inplace=True)\n",
    "    df_test.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    train_data=Dataset.from_pandas(df_train)\n",
    "    test_data=Dataset.from_pandas(df_test)\n",
    "    \n",
    "    tokenizer=AutoTokenizer.from_pretrained(args.model_checkpoint)\n",
    "    model=AutoModelForSequenceClassification.from_pretrained(args.model_checkpoint)\n",
    "\n",
    "    print()\n",
    "    print(f\"The maximal # input tokens : {tokenizer.model_max_length:,}\")\n",
    "    print(f\"Vocabulary size : {tokenizer.vocab_size:,}\")\n",
    "    print(f\"The # of parameters : {sum([p.nelement() for p in model.parameters()]):,}\")\n",
    "    print()\n",
    "    \n",
    "    train_module=utils.Loader_Creation(train_data, tokenizer,args.feature_name)\n",
    "    \n",
    "\n",
    "    test_module=utils.Loader_Creation(test_data, tokenizer,args.feature_name)\n",
    "\n",
    "    train_data.set_format(type=\"pandas\")\n",
    "    df_train=train_data[:]\n",
    "    train_data.reset_format()\n",
    "\n",
    "#     train_indices, val_indices=utils.mask_creation(df_train, 'churn', args.seed, args.validation_split)\n",
    "\n",
    "    \n",
    "\n",
    "#     train_sampler = SubsetRandomSampler(train_indices)\n",
    "#     valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "    train_dataloader=DataLoader(train_module,\n",
    "                                shuffle=True,\n",
    "                                batch_size=args.batch_size,\n",
    "                                collate_fn=train_module.collate_fn,\n",
    "                                drop_last=True   # longformer model bug\n",
    "                               )\n",
    "    \n",
    "#     train_dataloader=DataLoader(train_module,\n",
    "#                                 sampler=train_sampler,\n",
    "#                                 batch_size=args.batch_size,\n",
    "#                                 collate_fn=train_module.collate_fn,\n",
    "#                                 drop_last=True   # longformer model bug\n",
    "#                                )\n",
    "\n",
    "#     valid_dataloader=DataLoader(train_module,\n",
    "#                                 sampler=valid_sampler,\n",
    "#                                 batch_size=args.batch_size,\n",
    "#                                 collate_fn=train_module.collate_fn\n",
    "#                                )\n",
    "\n",
    "    test_dataloader=DataLoader(test_module,\n",
    "                                shuffle=False,\n",
    "                                batch_size=args.batch_size,\n",
    "                                collate_fn=test_module.collate_fn\n",
    "                               )\n",
    "\n",
    "    # %pdb\n",
    "    # next(iter(train_dataloader))\n",
    "\n",
    "    print()\n",
    "    print('{:<30}{:<10,} '.format(\"training mini-batch\",len(train_dataloader)))\n",
    "#     print('{:<30}{:<10,} '.format(\"validation mini-batch\",len(valid_dataloader)))\n",
    "    print('{:<30}{:<10,} '.format(\"test mini-batch\",len(test_dataloader)))\n",
    "    \n",
    "    train_label=df_train['churn'].values.squeeze()\n",
    "    num_classes=np.unique(train_label).shape[0]\n",
    "    if args.loss_weight:\n",
    "        train_classes_num, train_classes_weight = utils.get_class_count_and_weight(train_label,num_classes)\n",
    "        loss_weight=torch.tensor(train_classes_weight).to(device)\n",
    "    else:\n",
    "        loss_weight=None\n",
    "        \n",
    "\n",
    "    t_total = int((len(train_dataloader) // args.batch_size)//args.gradient_accumulation_steps*float(args.num_epochs))\n",
    "\n",
    "    warmup_steps=int((len(train_dataloader) // args.batch_size)//args.gradient_accumulation_steps*args.warmup_ratio)\n",
    "\n",
    "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_grouped_parameters = [\n",
    "                {\n",
    "                    \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "                    \"weight_decay\": args.weight_decay,\n",
    "                },\n",
    "                {\n",
    "                    \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "                    \"weight_decay\": 0.0,\n",
    "                },\n",
    "            ]\n",
    "\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=args.lr, eps=args.adam_epsilon)\n",
    "    # optimizer=AdamW(model.parameters(),lr=args.lr)\n",
    "    #     lr_scheduler =get_linear_schedule_with_warmup(optimizer, \n",
    "    #                                                   num_warmup_steps=warmup_steps, \n",
    "    #                                                   num_training_steps=t_total\n",
    "    #                                                  )\n",
    "\n",
    "    lr_scheduler = get_scheduler(name=args.lr_scheduler_type, \n",
    "                                 optimizer=optimizer,\n",
    "                                 num_warmup_steps=warmup_steps,\n",
    "                                 num_training_steps=t_total)\n",
    "    \n",
    "    accelerator = Accelerator(fp16=args.fp16)\n",
    "    acc_state = {str(k): str(v) for k, v in accelerator.state.__dict__.items()}\n",
    "    if accelerator.is_main_process:\n",
    "        accelerator.print(\"\")\n",
    "        logger.info(f'Accelerator Config: {acc_state}')\n",
    "        accelerator.print(\"\")\n",
    "    \n",
    "#     model, optimizer, train_dataloader, valid_dataloader, test_dataloader = accelerator.prepare(\n",
    "#         model, optimizer, train_dataloader, valid_dataloader, test_dataloader\n",
    "#     )\n",
    "    \n",
    "    model, optimizer, train_dataloader, test_dataloader = accelerator.prepare(\n",
    "        model, optimizer, train_dataloader, test_dataloader\n",
    "    )\n",
    "    \n",
    "    best_metric = float('inf')\n",
    "    # best_metric = 0\n",
    "    \n",
    "    iter_tput = []\n",
    "    \n",
    "    for epoch in tqdm(range(args.num_epochs),position=0 ,leave=True):\n",
    "        \n",
    "        accelerator.print(f\"\\n===========EPOCH {epoch+1}/{args.num_epochs}===============\\n\")\n",
    "        model.train()\n",
    "                \n",
    "        losses=[]\n",
    "        for step,batch in enumerate(train_dataloader):\n",
    "            t0=time.time()\n",
    "            batch={k:v.type(torch.LongTensor).to(accelerator.device) for k,v in batch.items()}\n",
    "            outputs=model(**batch)\n",
    "#             loss=outputs.loss\n",
    "            logits=outputs['logits']\n",
    "            \n",
    "#             print(step,outputs,logits.view(-1, num_classes))\n",
    "            \n",
    "            if loss_weight is None:\n",
    "                loss = F.cross_entropy(logits.view(-1, num_classes).to(accelerator.device), \n",
    "                                       batch[\"labels\"])\n",
    "            else:\n",
    "                loss = F.cross_entropy(logits.view(-1, num_classes).to(accelerator.device), \n",
    "                                       batch[\"labels\"], weight=loss_weight.float().to(accelerator.device)) \n",
    "            \n",
    "            accelerator.backward(loss)\n",
    "            if (step+1)%args.gradient_accumulation_steps == 0 or step==len(train_dataloader)-1:\n",
    "                optimizer.step()\n",
    "                if args.use_schedule:\n",
    "                    lr_scheduler.step()\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "            losses.append(loss.item())\n",
    "            \n",
    "            iter_tput.append(batch[\"input_ids\"].shape[0] / (time.time() - t0))\n",
    "            \n",
    "            if step%(len(train_dataloader)//10)==0 and not step==0 :\n",
    "                accelerator.print('Epoch {:05d} | Step {:05d} | Loss {:.4f} | Speed (samples/sec) {:.2f} | GPU{:.0f} MB'\n",
    "                                  .format(epoch, step, np.mean(losses[-10:]), np.mean(iter_tput[3:]), \n",
    "                                          torch.cuda.max_memory_allocated() / 1000000))\n",
    "\n",
    "#         epoch_loss=np.mean(losses)\n",
    "#         accelerator.print(f\"\\n** avg_loss : {epoch_loss:.2f}, time :~ {(time.time()-t0)//60} min ({time.time()-t0 :.2f} sec)***\\n\")\n",
    "\n",
    "        t1=time.time()\n",
    "        train_pred,train_target,train_losses=utils.eval_func(train_dataloader,\n",
    "                                                             model, \n",
    "                                                             accelerator.device,\n",
    "                                                             num_classes=num_classes, \n",
    "                                                             loss_weight=loss_weight)\n",
    "\n",
    "        avg_train_loss=np.mean(train_losses)\n",
    "\n",
    "        train_output=utils.model_evaluate(train_target.reshape(-1),train_pred)\n",
    "\n",
    "\n",
    "        t2=time.time()\n",
    "        accelerator.print(\"\")\n",
    "        accelerator.print(\"==> Running Validation on training set \\n\")\n",
    "        accelerator.print(\"\")\n",
    "        accelerator.print(\"avg_loss: {:.6f} | True_Prediction: {:,} | False_Prediction: {:,} | accuracy: {:.2%} | precision: {:.2%} | recall: {:.2%} | F1_score: {:.2%} | ROC_AUC: {:.1%} | PR_AUC: {:.1%} | Elapsed: {:}\".\\\n",
    "               format(avg_train_loss, train_output[\"true_prediction\"], train_output[\"false_prediction\"], train_output[\"accuracy\"], \\\n",
    "                     train_output[\"precision\"], train_output[\"recall\"], train_output[\"f1_score\"], train_output[\"AUC\"], train_output[\"pr_auc\"], \\\n",
    "                      utils.format_time(t2-t1)))\n",
    "        if accelerator.is_main_process:\n",
    "            gain_1=train_output[\"GAIN\"][\"1%\"]\n",
    "            gain_5=train_output[\"GAIN\"][\"5%\"]\n",
    "            gain_10=train_output[\"GAIN\"][\"10%\"]\n",
    "            with open(os.path.join(os.getcwd(),\"metrics_training.txt\"),'a') as f:\n",
    "                f.write(f'{args.model_output_name},{epoch},{avg_train_loss},{train_output[\"true_prediction\"]},{train_output[\"false_prediction\"]},{train_output[\"accuracy\"]},{train_output[\"precision\"]},{train_output[\"recall\"]},{train_output[\"f1_score\"]},{gain_1},{gain_5},{gain_10},{train_output[\"AUC\"]},{train_output[\"pr_auc\"]}\\n')    \n",
    "\n",
    "        t3=time.time()\n",
    "        \n",
    "        test_pred,test_target,test_losses=utils.eval_func(test_dataloader,model,accelerator.device)\n",
    "        avg_test_loss=np.mean(test_losses)\n",
    "        test_output=utils.model_evaluate(test_target.reshape(-1),test_pred)\n",
    "\n",
    "        t4=time.time()\n",
    "        accelerator.print(\"\")\n",
    "        accelerator.print(\"==> Running Validation on test set \\n\")\n",
    "        accelerator.print(\"\")\n",
    "        accelerator.print(\"avg_loss: {:.6f} | True_Prediction: {:,} | False_Prediction: {:,} | accuracy: {:.2%} | precision: {:.2%} | recall: {:.2%} | F1_score: {:.2%} | ROC_AUC: {:.1%} | PR_AUC: {:.1%} | Elapsed: {:}\".\\\n",
    "               format(avg_test_loss, test_output[\"true_prediction\"], test_output[\"false_prediction\"], test_output[\"accuracy\"], \\\n",
    "                     test_output[\"precision\"], test_output[\"recall\"], test_output[\"f1_score\"], test_output[\"AUC\"], test_output[\"pr_auc\"], \\\n",
    "                      utils.format_time(t4-t3)))  \n",
    "\n",
    "        if accelerator.is_main_process:\n",
    "            gain_1=test_output[\"GAIN\"][\"1%\"]\n",
    "            gain_5=test_output[\"GAIN\"][\"5%\"]\n",
    "            gain_10=test_output[\"GAIN\"][\"10%\"]\n",
    "            with open(os.path.join(os.getcwd(),\"metrics_test.txt\"),'a') as f:\n",
    "                f.write(f'{args.model_output_name},{epoch},{avg_test_loss},{test_output[\"true_prediction\"]},{test_output[\"false_prediction\"]},{test_output[\"accuracy\"]},{test_output[\"precision\"]},{test_output[\"recall\"]},{test_output[\"f1_score\"]},{gain_1},{gain_5},{gain_10},{test_output[\"AUC\"]},{test_output[\"pr_auc\"]}\\n')    \n",
    "\n",
    "        if accelerator.is_main_process:\n",
    "            if not os.path.exists(args.output_dir):\n",
    "                os.makedirs(args.output_dir)\n",
    "                \n",
    "        selected_metric=avg_test_loss\n",
    "        if selected_metric<best_metric:\n",
    "            best_metric=selected_metric\n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(model)\n",
    "            unwrapped_model.save_pretrained(args.output_dir, save_function=accelerator.save)\n",
    "            if accelerator.is_main_process:\n",
    "                tokenizer.save_pretrained(args.output_dir)\n",
    "                accelerator.print(\"\")\n",
    "                logger.info(f'Performance improve after epoch: {epoch+1} ... ')\n",
    "                accelerator.print(\"\")                \n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    parser = argparse.ArgumentParser(description='BERT Model')\n",
    "    parser.add_argument('--gpus', type=int, default=[0,1], nargs='+', help='used gpu')\n",
    "    parser.add_argument(\"--shuffle_train\",  type=bool,default=True,help=\"shuffle data or not\")\n",
    "    parser.add_argument(\"--validation_split\",  type=float,default=0.2,help=\"The split ratio for validation dataset\")\n",
    "    parser.add_argument(\"--loss_weight\", action='store_true', help=\"weight for unbalance data\")\n",
    "    parser.add_argument(\"--undersampling\", action=\"store_true\", help=\"undersampling or not\")\n",
    "    parser.add_argument(\"--train_negative_positive_ratio\",  type=int,default=4,help=\"Undersampling negative vs position ratio in training\")\n",
    "    parser.add_argument(\"--test_negative_positive_ratio\",  type=int,default=10,help=\"Undersampling negative vs position ratio in test set\")\n",
    "    parser.add_argument(\"--seed\",  type=int,default=101,\n",
    "            help=\"random seed for np.random.seed, torch.manual_seed and torch.cuda.manual_seed.\")\n",
    "\n",
    "    parser.add_argument(\"--truncation_strategy\", type=str, default=\"tail\",help=\"how to truncate the long length email\")\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=20)\n",
    "    parser.add_argument('--num_epochs', type=int, default=10)\n",
    "    parser.add_argument(\"--gradient_accumulation_steps\",type=int,default=8,\n",
    "                               help=\"Number of updates steps to accumulate before performing a backward/update pass.\")\n",
    "    parser.add_argument('--lr', type=float, default=2e-5, help=\"learning rate\")\n",
    "    parser.add_argument('--lr_scheduler_type', type=str, default=\"linear\")\n",
    "    #     parser.add_argument('--lr_scheduler_type', type=str, default=\"cosine\")\n",
    "    parser.add_argument(\"--fp16\", action=\"store_true\", help=\"If passed, will use FP16 training.\")\n",
    "    parser.add_argument('--use_schedule', action=\"store_true\")\n",
    "    parser.add_argument(\"--weight_decay\", default=1e-4, type=float, help=\"Weight decay if we apply some.\")\n",
    "    parser.add_argument(\"--adam_epsilon\", default=1e-8, type=float, help=\"Epsilon for Adam optimizer.\")\n",
    "    parser.add_argument(\"--warmup_ratio\", default=0.4, type=float, help=\"Linear warmup over warmup_steps.\")\n",
    "    parser.add_argument('--model_checkpoint', type=str, default=\"roberta-base\")\n",
    "    parser.add_argument(\"--output_dir\", default=os.path.join(os.getcwd(),\"bert_repo\"), type=str, help=\"output folder name\")\n",
    "    parser.add_argument(\"--model_output_name\", default=\"bert\", type=str)\n",
    "    parser.add_argument(\"--feature_name\", default=\"Full_TextBody\", type=str)\n",
    "    parser.add_argument(\"--data\", default=\"Full_TextBody_truncation_tail_bert\", type=str)\n",
    "    parser.add_argument(\"--frozen_layers\", type=int, default=6,help=\"freeze layers without gradient updates\")  \n",
    "\n",
    "    args,_ = parser.parse_known_args()\n",
    "\n",
    "    args.model_output_name=f'{args.model_output_name}_{args.feature_name}_{args.truncation_strategy}'\n",
    "    args.output_dir=f'{args.output_dir}_{args.feature_name}_{args.truncation_strategy}'\n",
    "\n",
    "    seed_everything(args.seed)\n",
    "\n",
    "    print()\n",
    "    print(args)\n",
    "    print()\n",
    "\n",
    "    data_dir=os.path.join(os.getcwd(),\"dataset\",args.data)\n",
    "    email_all=load_from_disk(data_dir)\n",
    "    email_all=email_all.filter(lambda x: x[args.feature_name]!=None)\n",
    "\n",
    "    train_data=email_all['train'].shuffle(seed=101).select(range(1200))\n",
    "    test_data=email_all['test'].shuffle(seed=101).select(range(500))\n",
    "\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = ','.join(str(x) for x in args.gpus)\n",
    "    # print(f\"The number of GPUs is {torch.cuda.device_count()}\")\n",
    "    if torch.cuda.is_available():    \n",
    "        device = torch.device(\"cuda\")\n",
    "        print()\n",
    "        print('{:<30}{:<10}'.format(\"The # of availabe GPU(s): \",torch.cuda.device_count()))\n",
    "\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            print('{:<30}{:<10}'.format(\"GPU Name: \",torch.cuda.get_device_name(i)))\n",
    "\n",
    "    else:\n",
    "        print('No GPU available, using the CPU instead.')\n",
    "        device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "63f69c0d-c090-4336-b62e-2b4c09f289ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"roberta-base\"\n",
    "tokenizer=AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9a1b5ee0-2cb2-4a9f-b152-a13b57df7413",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The maximal # input tokens : 512\n",
      "Vocabulary size : 50,265\n",
      "The # of parameters : 124,647,170\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75397a10ee054060910371feb6888b41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25a18dccede74ba18edf894532e597f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data.set_format(type=\"pandas\")\n",
    "df_train=train_data[:]\n",
    "test_data.set_format(type=\"pandas\")\n",
    "df_test=test_data[:]\n",
    "\n",
    "## undersample netative sample so that the negative/positive=4\n",
    "if args.undersampling:\n",
    "    df_train=utils.under_sampling(df_train,'churn', args.seed, args.train_negative_positive_ratio)\n",
    "    df_test=utils.under_sampling(df_test,'churn', args.seed, args.test_negative_positive_ratio)\n",
    "    df_train.reset_index(drop=True, inplace=True)\n",
    "    df_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "train_data=Dataset.from_pandas(df_train)\n",
    "test_data=Dataset.from_pandas(df_test)\n",
    "\n",
    "tokenizer=AutoTokenizer.from_pretrained(args.model_checkpoint)\n",
    "model=AutoModelForSequenceClassification.from_pretrained(args.model_checkpoint)\n",
    "\n",
    "print()\n",
    "print(f\"The maximal # input tokens : {tokenizer.model_max_length:,}\")\n",
    "print(f\"Vocabulary size : {tokenizer.vocab_size:,}\")\n",
    "print(f\"The # of parameters : {sum([p.nelement() for p in model.parameters()]):,}\")\n",
    "print()\n",
    "\n",
    "train_module=utils.Loader_Creation(train_data, tokenizer,args.feature_name)\n",
    "\n",
    "\n",
    "test_module=utils.Loader_Creation(test_data, tokenizer,args.feature_name)\n",
    "\n",
    "train_data.set_format(type=\"pandas\")\n",
    "df_train=train_data[:]\n",
    "train_data.reset_format()\n",
    "\n",
    "#     train_indices, val_indices=utils.mask_creation(df_train, 'churn', args.seed, args.validation_split)\n",
    "\n",
    "\n",
    "\n",
    "#     train_sampler = SubsetRandomSampler(train_indices)\n",
    "#     valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_dataloader=DataLoader(train_module,\n",
    "                            shuffle=True,\n",
    "                            batch_size=args.batch_size,\n",
    "                            collate_fn=train_module.collate_fn,\n",
    "                            drop_last=True   # longformer model bug\n",
    "                           )\n",
    "\n",
    "#     train_dataloader=DataLoader(train_module,\n",
    "#                                 sampler=train_sampler,\n",
    "#                                 batch_size=args.batch_size,\n",
    "#                                 collate_fn=train_module.collate_fn,\n",
    "#                                 drop_last=True   # longformer model bug\n",
    "#                                )\n",
    "\n",
    "#     valid_dataloader=DataLoader(train_module,\n",
    "#                                 sampler=valid_sampler,\n",
    "#                                 batch_size=args.batch_size,\n",
    "#                                 collate_fn=train_module.collate_fn\n",
    "#                                )\n",
    "\n",
    "test_dataloader=DataLoader(test_module,\n",
    "                            shuffle=False,\n",
    "                            batch_size=args.batch_size,\n",
    "                            collate_fn=test_module.collate_fn\n",
    "                           )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "720c8d72-9bc8-4cca-b970-3597cb31029b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The # of parameters to be updated : 43,119,362\n"
     ]
    }
   ],
   "source": [
    "model=AutoModelForSequenceClassification.from_pretrained(args.model_checkpoint)\n",
    "\n",
    "modules = [model.base_model.embeddings, *model.base_model.encoder.layer[:args.frozen_layers]] \n",
    "for module in modules:\n",
    "    for param in module.parameters():\n",
    "        param.requires_grad = False\n",
    "print(f\"The # of parameters to be updated : {sum([p.nelement() for p in model.parameters() if p.requires_grad==True]):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6efebd46-83e6-4a3f-94c8-0868107bd4f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertEmbeddings(\n",
       "  (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "  (position_embeddings): Embedding(512, 768)\n",
       "  (token_type_embeddings): Embedding(2, 768)\n",
       "  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.base_model.embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb78fa4-f0a9-4b88-b92b-fe45f22a2249",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74177f92-9f87-4a05-a11c-fe064f89df7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ec2-user/SageMaker/retention_model_NLP/v1_src/bert_repo'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(os.getcwd(),\"bert_repo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2089949-7fc2-4302-8272-dde1da963212",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32106e06-87b2-4528-95d3-78ba9d97a0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ConvNextModel, ConvNextConfig\n",
    "\n",
    "# Initializing a ConvNext convnext-tiny-224 style configuration\n",
    "configuration = ConvNextConfig()\n",
    "# Initializing a model from the convnext-tiny-224 style configuration\n",
    "model = ConvNextModel(configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c8f0edf-f511-4289-a0ab-7a8ff5cf9d66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.arange(0, 5).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e7819f1-680b-4739-b769-7dc2ec9128d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e+00, 1.5849e-01, 2.5119e-02, 3.9811e-03, 6.3096e-04])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_model=10\n",
    "import math\n",
    "torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f1d6dee-4209-4032-b005-7c70a541d875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b614731-4790-4fa7-a018-15ccd88eddb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 1]), torch.Size([1, 5]), torch.Size([5, 5]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len=5\n",
    "position = torch.arange(0, max_len).unsqueeze(1)\n",
    "div_term=torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model)).unsqueeze(0)\n",
    "position.shape, div_term.shape, (position*div_term).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb5a4978-9663-47be-a520-5f26f7555d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 5])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "37265f6a-d03f-489a-8020-48f1f2a3bdae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6988, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randn(10, 2, requires_grad=True)\n",
    "target = torch.randint(0,2,size=(10,), requires_grad=False)\n",
    "loss = F.cross_entropy(torch.sigmoid(input), target)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c0116aef-a539-440a-afe8-8bf92bccfd02",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Using a target size (torch.Size([10, 1])) that is different to the input size (torch.Size([10, 2])) is deprecated. Please ensure they have the same size.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_37883/4208436696.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2884\u001b[0m         raise ValueError(\n\u001b[1;32m   2885\u001b[0m             \u001b[0;34m\"Using a target size ({}) that is different to the input size ({}) is deprecated. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2886\u001b[0;31m             \u001b[0;34m\"Please ensure they have the same size.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2887\u001b[0m         )\n\u001b[1;32m   2888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Using a target size (torch.Size([10, 1])) that is different to the input size (torch.Size([10, 2])) is deprecated. Please ensure they have the same size."
     ]
    }
   ],
   "source": [
    "target = torch.randint(0,2,size=(10,1), requires_grad=False)\n",
    "F.binary_cross_entropy(torch.sigmoid(input), target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0a89955c-95cd-48e0-9d75-103ef76ae928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bc978a99-e1ee-4986-9e81-249f969d7453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2378854625550661"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.1350*2)/1.1350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c52e0d-5158-4265-86cd-08001ea70783",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_pytorch_latest_p37",
   "language": "python",
   "name": "conda_amazonei_pytorch_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
