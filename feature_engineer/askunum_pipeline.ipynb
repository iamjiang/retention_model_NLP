{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd1e64ba-77d7-4fb3-b36f-864a4171b2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "pd.set_option('max_columns', 500)\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from functools import reduce\n",
    "en_stopwords = set(stopwords.words('english')) \n",
    "import itertools\n",
    "import time\n",
    "import re\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "653e3335-fcbc-466c-b650-01f6ac994477",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_folder=\"s3://trident-retention-output/\"\n",
    "folder = 's3://trident-retention-data/askunum/'\n",
    "output_dir=os.path.join(os.getcwd(),'outputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5183e99d-32d0-4ef8-aa33-8483a641965a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = pd.read_csv(folder + 'askunum_2022_1.csv', nrows=5)\n",
    "# for i in x.loc[x.ParentId=='5003x00002GuQ6tAAF'].sort_values('MessageDate', ascending=False)['TextBody']: \n",
    "#     print('-'*200)\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac80f799-a0f6-4295-a9c8-d4314344e4be",
   "metadata": {},
   "source": [
    "## id counts and issue durations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb5799f-e5ed-445e-8c2c-b12b8f07835d",
   "metadata": {},
   "source": [
    "#### load the data, process into issue durations and counts\n",
    "- data format for each year is a bit different. Thus, we standardize and then apply the function to obtain counts and durations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5087993c-00ce-4e67-91d5-b979c695a9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_askunum_df(folder, year, usecols=None, nrows=None): \n",
    "    if year == 2018: # ['ID', 'PARENTID', 'PARENT.CREATEDDATE', 'PARENT.CLOSEDDATE']\n",
    "        askunum_df = pd.read_csv(folder + 'askunum_2018.csv', encoding='latin-1', usecols=usecols, nrows=nrows)\n",
    "       \n",
    "    if year == 2019: \n",
    "        askunum_df = pd.concat([pd.read_csv(folder + 'askunum_2019_{}.csv'.format(i), encoding='latin-1', usecols=usecols, nrows=nrows) for i in range(1, 4)]) \n",
    "        \n",
    "    if year == 2020:  \n",
    "        askunum_df = pd.concat([pd.read_csv(folder + 'unnested_2020_{}_customer.csv'.format(i), encoding='latin-1', usecols=usecols, nrows=nrows) for i in range(10)])\n",
    "\n",
    "    if year == 2021: \n",
    "        askunum_df = pd.concat([pd.read_csv(folder + 'unnested_2021_{}_customer.csv'.format(i), encoding='latin-1', usecols=usecols, nrows=nrows) for i in range(10)]) \n",
    "        \n",
    "    if year == 2022: \n",
    "        askunum_df = pd.concat([pd.read_csv(folder + 'askunum_2022_{}.csv'.format(i), encoding='latin-1', usecols=usecols, nrows=nrows) for i in range(0, 4)])\n",
    "        \n",
    "    return askunum_df\n",
    "\n",
    "def pipeline_askunum_counts_and_duration(folder, year, usecols=False, parent_id=False, target_columns=False): \n",
    "    if target_columns == False: \n",
    "        target_columns = ['Id', 'ParentId', 'CreatedDate', 'ClosedDate', 'account_id']\n",
    "    \n",
    "    def helper_get_counts_and_duration(askunum_df):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            askunum_df (pd.DataFrame): dataframe with ['Id', 'ParentId', 'account_id', 'CreatedDate', 'ClosedDate'] as columns\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame with ['account_id', 'year', 'month', 'id_count', 'parent_id_count', 'askunum_days']\n",
    "        \"\"\"\n",
    "        # issue counts by created date\n",
    "        askunum_df['CreatedDate'] = pd.to_datetime(askunum_df['CreatedDate'])\n",
    "        askunum_df['year'] = askunum_df.CreatedDate.apply(lambda x: x.year)\n",
    "        askunum_df['month'] = askunum_df.CreatedDate.apply(lambda x: x.month)\n",
    "        \n",
    "        email_counts_by_month = askunum_df.groupby(['account_id', 'year', 'month'])[['Id']].count()\n",
    "        issue_counts_by_month = askunum_df.drop('Id', axis=1).drop_duplicates().groupby(['account_id', 'year', 'month'])[['ParentId']].count()\n",
    "        combined_df = email_counts_by_month.join(issue_counts_by_month)\n",
    "        combined_df.rename({\"Id\":'askunum_id_count', 'ParentId':'askunum_parentid_count'}, axis=1, inplace=True)\n",
    "        email_counts_by_month, issue_counts_by_month = None, None\n",
    "        \n",
    "        # completed issue durations\n",
    "        askunum_df = askunum_df.loc[~askunum_df.ClosedDate.isna()]\n",
    "        askunum_df['ClosedDate'] = pd.to_datetime(askunum_df['ClosedDate'])\n",
    "        askunum_df['askunum_days'] = (askunum_df['ClosedDate'] - askunum_df['CreatedDate']).apply(lambda x: (x.days * 24 + x.seconds / 3600)/24)\n",
    "        issue_days_by_month = askunum_df.groupby(['account_id', 'year', 'month'])[['askunum_days']].sum()\n",
    "        combined_df = combined_df.join(issue_days_by_month, how='outer')\n",
    "        combined_df[['askunum_id_count', 'askunum_parentid_count', 'askunum_days']].fillna(0, inplace=True)\n",
    "        \n",
    "        return combined_df \n",
    "    \n",
    "    if year in [2018, 2019]: \n",
    "        if usecols==False: \n",
    "            usecols = ['ID', 'PARENTID', 'PARENT.CREATEDDATE', 'PARENT.CLOSEDDATE']\n",
    "        if parent_id==False: \n",
    "            parent_id = 'PARENTID'\n",
    "     \n",
    "    if year in [2020, 2021]: \n",
    "        if usecols==False: \n",
    "            usecols = ['Id', 'ParentId', 'CreatedDate', 'ClosedDate']\n",
    "        if parent_id==False: \n",
    "            parent_id = 'ParentId'\n",
    "            \n",
    "    if year in [2022]: \n",
    "        if usecols==False: \n",
    "            usecols = ['Id', 'ParentId', 'Parent.CreatedDate', 'Parent.ClosedDate']\n",
    "        if parent_id==False: \n",
    "            parent_id = 'ParentId'\n",
    "            \n",
    "    askunum_df = load_askunum_df(folder, year, usecols=usecols).rename({parent_id: 'ParentId'}, axis=1) #use ParentId as the standard\n",
    "    account_mapping = pd.read_csv(folder + '{}ParentAccount.csv'.format(year), usecols=['ParentId', 'Parent.AccountId']).drop_duplicates().dropna()\n",
    "    askunum_df = pd.merge(askunum_df, account_mapping, on='ParentId')\n",
    "    cols = ['ParentId' if i == parent_id else i for i in usecols] + ['Parent.AccountId']\n",
    "    print(target_columns, cols)\n",
    "    askunum_df = askunum_df.rename(dict(zip(cols, target_columns)), axis=1)\n",
    "    print(askunum_df.shape)\n",
    "     \n",
    "    askunum_features = helper_get_counts_and_duration(askunum_df)\n",
    "    askunum_features.to_csv(os.path.join(output_dir , 'askunum_issue_count_and_duration_{}.csv'.format(year)))\n",
    "    print(askunum_features.shape)\n",
    "    return askunum_df, askunum_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2222de5-6396-4eee-9c12-cfaa999b129e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: \n",
    "    pipeline_askunum_counts_and_duration(folder, 2018)\n",
    "    pipeline_askunum_counts_and_duration(folder, 2019)\n",
    "    pipeline_askunum_counts_and_duration(folder, 2020)\n",
    "    pipeline_askunum_counts_and_duration(folder, 2021)\n",
    "x = pipeline_askunum_counts_and_duration(folder, 2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e787c199-6410-4f9b-8c2e-3a76bf8cf34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at the df and the features\n",
    "x[0].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_pytorch_latest_p37",
   "language": "python",
   "name": "conda_amazonei_pytorch_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
